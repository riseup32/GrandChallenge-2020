{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from preprocessing import convert_spectrograms, convert_tensor\n",
    "from model_ae import Encoder, Decoder, Discriminator\n",
    "from utils.optimization import WarmupLinearSchedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'aae'\n",
    "conv_dim = '1d'\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "\n",
    "use_warmup = True\n",
    "gradient_accumulation_steps = 1\n",
    "warmup_proportion = 0.1\n",
    "\n",
    "multi_gpu = True\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_z = 800 if (conv_dim == '1d') else 1408\n",
    "if(multi_gpu):\n",
    "    batch_size = batch_size * torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1440"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data_repo = os.path.join('.', 'wav_data', 'pretrain')\n",
    "\n",
    "samples_data = glob.glob(os.path.join(sample_data_repo, '**', '*wav'), recursive=True)\n",
    "samples_data = sorted(samples_data)\n",
    "len(samples_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "idx = np.random.permutation(len(samples_data))\n",
    "train_idx = idx[:int(len(samples_data)*0.8)]\n",
    "eval_idx = idx[int(len(samples_data)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = list(np.array(samples_data)[train_idx])\n",
    "eval_samples = list(np.array(samples_data)[eval_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1152, 288)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_samples), len(eval_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1152/1152 [03:24<00:00,  5.63it/s]\n",
      "100%|██████████| 288/288 [00:51<00:00,  5.58it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = convert_spectrograms(train_samples, conv_dim=conv_dim)\n",
    "X_eval = convert_spectrograms(eval_samples, conv_dim=conv_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = convert_tensor(X_train, device=device)\n",
    "X_eval = convert_tensor(X_eval, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(X_train, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)\n",
    "eval_dataloader = DataLoader(X_eval, batch_size=batch_size, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(multi_gpu == True):\n",
    "    encoder = Encoder(conv_dim=conv_dim)\n",
    "    decoder = Decoder(conv_dim=conv_dim)\n",
    "    encoder = torch.nn.DataParallel(encoder).cuda()\n",
    "    decoder = torch.nn.DataParallel(decoder).cuda()\n",
    "    if(model == 'aae'):\n",
    "        discriminator = Discriminator(conv_dim=conv_dim)\n",
    "        discriminator = torch.nn.DataParallel(discriminator).cuda()\n",
    "else:\n",
    "    encoder = Encoder(conv_dim=conv_dim).to(device)\n",
    "    decoder = Decoder(conv_dim=conv_dim).to(device)\n",
    "    if(model == 'aae'):\n",
    "        discriminator = Discriminator(conv_dim=conv_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_grad():\n",
    "    encoder.zero_grad()\n",
    "    decoder.zero_grad()\n",
    "    if(model == 'aae'):\n",
    "        discriminator.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss()\n",
    "enc_opt = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "dec_opt = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "if(model == 'aae'):\n",
    "    disc_opt = optim.Adam(discriminator.parameters(), lr=learning_rate*0.1)\n",
    "\n",
    "if(use_warmup == True):\n",
    "    t_total = len(train_dataloader) // gradient_accumulation_steps * num_epochs\n",
    "    enc_scheduler = WarmupLinearSchedule(enc_opt, warmup_steps=t_total * warmup_proportion, t_total=t_total)\n",
    "    dec_scheduler = WarmupLinearSchedule(dec_opt, warmup_steps=t_total * warmup_proportion, t_total=t_total)\n",
    "    disc_scheduler = WarmupLinearSchedule(disc_opt, warmup_steps=t_total * warmup_proportion, t_total=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, eval_dataloader, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        ### Train step\n",
    "        tr_recon_loss = 0\n",
    "        nb_train_steps = 0\n",
    "\n",
    "        for X_batch in train_dataloader:\n",
    "            ## Reconstruction\n",
    "            X = Variable(X_batch)\n",
    "            if cuda:\n",
    "                X = X.cuda()\n",
    "\n",
    "            z_sample = encoder(X)\n",
    "            X_sample = decoder(z_sample)\n",
    "            \n",
    "            recon_loss = loss_func(X_sample, X)\n",
    "\n",
    "            recon_loss.backward()\n",
    "            dec_opt.step()\n",
    "            enc_opt.step()\n",
    "            reset_grad()\n",
    "            \n",
    "            tr_recon_loss += recon_loss.mean().item()\n",
    "            nb_train_steps += 1\n",
    "\n",
    "            if(model == 'aae'):\n",
    "                ## Discriminator\n",
    "                for _ in range(5):\n",
    "                    z_fake = Variable(torch.randn(batch_size, n_z))\n",
    "                    if cuda:\n",
    "                        z_fake = z_fake.cuda()\n",
    "\n",
    "                    z_real = encoder(X).view(batch_size, -1)\n",
    "\n",
    "                    D_fake = discriminator(z_fake)\n",
    "                    D_real = discriminator(z_real)\n",
    "\n",
    "                    D_loss = -(torch.mean(D_real) - torch.mean(D_fake))\n",
    "\n",
    "                    D_loss.backward()\n",
    "                    disc_opt.step()\n",
    "\n",
    "                    # Weight clipping\n",
    "                    for p in discriminator.parameters():\n",
    "                        p.data.clamp_(-0.01, 0.01)\n",
    "\n",
    "                    reset_grad()\n",
    "\n",
    "                ## Generator\n",
    "                z_real = encoder(X).view(batch_size, -1)\n",
    "                D_real = discriminator(z_real)\n",
    "\n",
    "                G_loss = -torch.mean(D_real)\n",
    "\n",
    "                G_loss.backward()\n",
    "                enc_opt.step()\n",
    "                reset_grad()\n",
    "                \n",
    "                if(use_warmup == True):\n",
    "                    enc_scheduler.step()\n",
    "                    dec_scheduler.step()\n",
    "                    disc_scheduler.step()\n",
    "                \n",
    "\n",
    "        tr_recon_loss = tr_recon_loss / nb_train_steps\n",
    "            \n",
    "        ### Evaluate step\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        if(model == 'aae'):\n",
    "            discriminator.eval()\n",
    "        eval_recon_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "        \n",
    "        for X_batch in eval_dataloader:\n",
    "            with torch.no_grad():\n",
    "                z_sample = encoder(X_batch)\n",
    "                X_sample = decoder(z_sample)\n",
    "            \n",
    "            tmp_eval_loss = loss_func(X_sample, X_batch)\n",
    "            eval_recon_loss += tmp_eval_loss.mean().item()\n",
    "            nb_eval_steps += 1\n",
    "            \n",
    "        eval_recon_loss = eval_recon_loss / nb_eval_steps\n",
    "            \n",
    "        \n",
    "        for param_group in enc_opt.param_groups:\n",
    "            lr = param_group['lr']\n",
    "        print('epoch: {:3d},    lr={:6f},    loss={:5f},    eval_loss={:5f}'\n",
    "              .format(epoch+1, lr, tr_recon_loss, eval_recon_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1,    lr=0.000100,    loss=0.553253,    eval_loss=0.124530\n",
      "epoch:   2,    lr=0.000200,    loss=0.124531,    eval_loss=0.122389\n",
      "epoch:   3,    lr=0.000300,    loss=0.121527,    eval_loss=0.118092\n",
      "epoch:   4,    lr=0.000400,    loss=0.116297,    eval_loss=0.112291\n",
      "epoch:   5,    lr=0.000500,    loss=0.110005,    eval_loss=0.106661\n",
      "epoch:   6,    lr=0.000600,    loss=0.104989,    eval_loss=0.100832\n",
      "epoch:   7,    lr=0.000700,    loss=0.098941,    eval_loss=0.094782\n",
      "epoch:   8,    lr=0.000800,    loss=0.092672,    eval_loss=0.088312\n",
      "epoch:   9,    lr=0.000900,    loss=0.086230,    eval_loss=0.081469\n",
      "epoch:  10,    lr=0.001000,    loss=0.079145,    eval_loss=0.074454\n",
      "epoch:  11,    lr=0.000989,    loss=0.072399,    eval_loss=0.068063\n",
      "epoch:  12,    lr=0.000978,    loss=0.066531,    eval_loss=0.063028\n",
      "epoch:  13,    lr=0.000967,    loss=0.062055,    eval_loss=0.059557\n",
      "epoch:  14,    lr=0.000956,    loss=0.059633,    eval_loss=0.057560\n",
      "epoch:  15,    lr=0.000944,    loss=0.057972,    eval_loss=0.056563\n",
      "epoch:  16,    lr=0.000933,    loss=0.057410,    eval_loss=0.055933\n",
      "epoch:  17,    lr=0.000922,    loss=0.056324,    eval_loss=0.055324\n",
      "epoch:  18,    lr=0.000911,    loss=0.056050,    eval_loss=0.054709\n",
      "epoch:  19,    lr=0.000900,    loss=0.055331,    eval_loss=0.054131\n",
      "epoch:  20,    lr=0.000889,    loss=0.054726,    eval_loss=0.053595\n",
      "epoch:  21,    lr=0.000878,    loss=0.054313,    eval_loss=0.053084\n",
      "epoch:  22,    lr=0.000867,    loss=0.053673,    eval_loss=0.052589\n",
      "epoch:  23,    lr=0.000856,    loss=0.053179,    eval_loss=0.052108\n",
      "epoch:  24,    lr=0.000844,    loss=0.052867,    eval_loss=0.051640\n",
      "epoch:  25,    lr=0.000833,    loss=0.052341,    eval_loss=0.051192\n",
      "epoch:  26,    lr=0.000822,    loss=0.052136,    eval_loss=0.050756\n",
      "epoch:  27,    lr=0.000811,    loss=0.051513,    eval_loss=0.050336\n",
      "epoch:  28,    lr=0.000800,    loss=0.051123,    eval_loss=0.049926\n",
      "epoch:  29,    lr=0.000789,    loss=0.050589,    eval_loss=0.049525\n",
      "epoch:  30,    lr=0.000778,    loss=0.050217,    eval_loss=0.049133\n",
      "epoch:  31,    lr=0.000767,    loss=0.049749,    eval_loss=0.048739\n",
      "epoch:  32,    lr=0.000756,    loss=0.049390,    eval_loss=0.048347\n",
      "epoch:  33,    lr=0.000744,    loss=0.048754,    eval_loss=0.047972\n",
      "epoch:  34,    lr=0.000733,    loss=0.048847,    eval_loss=0.047604\n",
      "epoch:  35,    lr=0.000722,    loss=0.048249,    eval_loss=0.047237\n",
      "epoch:  36,    lr=0.000711,    loss=0.048188,    eval_loss=0.046875\n",
      "epoch:  37,    lr=0.000700,    loss=0.047886,    eval_loss=0.046523\n",
      "epoch:  38,    lr=0.000689,    loss=0.047224,    eval_loss=0.046179\n",
      "epoch:  39,    lr=0.000678,    loss=0.046951,    eval_loss=0.045841\n",
      "epoch:  40,    lr=0.000667,    loss=0.046786,    eval_loss=0.045508\n",
      "epoch:  41,    lr=0.000656,    loss=0.046391,    eval_loss=0.045177\n",
      "epoch:  42,    lr=0.000644,    loss=0.046182,    eval_loss=0.044852\n",
      "epoch:  43,    lr=0.000633,    loss=0.045869,    eval_loss=0.044532\n",
      "epoch:  44,    lr=0.000622,    loss=0.045452,    eval_loss=0.044214\n",
      "epoch:  45,    lr=0.000611,    loss=0.044852,    eval_loss=0.043905\n",
      "epoch:  46,    lr=0.000600,    loss=0.044892,    eval_loss=0.043604\n",
      "epoch:  47,    lr=0.000589,    loss=0.044398,    eval_loss=0.043307\n",
      "epoch:  48,    lr=0.000578,    loss=0.044173,    eval_loss=0.043009\n",
      "epoch:  49,    lr=0.000567,    loss=0.044004,    eval_loss=0.042711\n",
      "epoch:  50,    lr=0.000556,    loss=0.043477,    eval_loss=0.042420\n",
      "epoch:  51,    lr=0.000544,    loss=0.043566,    eval_loss=0.042128\n",
      "epoch:  52,    lr=0.000533,    loss=0.043056,    eval_loss=0.041836\n",
      "epoch:  53,    lr=0.000522,    loss=0.042901,    eval_loss=0.041555\n",
      "epoch:  54,    lr=0.000511,    loss=0.042440,    eval_loss=0.041285\n",
      "epoch:  55,    lr=0.000500,    loss=0.042224,    eval_loss=0.041021\n",
      "epoch:  56,    lr=0.000489,    loss=0.042195,    eval_loss=0.040762\n",
      "epoch:  57,    lr=0.000478,    loss=0.041652,    eval_loss=0.040513\n",
      "epoch:  58,    lr=0.000467,    loss=0.041209,    eval_loss=0.040268\n",
      "epoch:  59,    lr=0.000456,    loss=0.041332,    eval_loss=0.040027\n",
      "epoch:  60,    lr=0.000444,    loss=0.040821,    eval_loss=0.039790\n",
      "epoch:  61,    lr=0.000433,    loss=0.040892,    eval_loss=0.039560\n",
      "epoch:  62,    lr=0.000422,    loss=0.040631,    eval_loss=0.039337\n",
      "epoch:  63,    lr=0.000411,    loss=0.040326,    eval_loss=0.039120\n",
      "epoch:  64,    lr=0.000400,    loss=0.040331,    eval_loss=0.038908\n",
      "epoch:  65,    lr=0.000389,    loss=0.039981,    eval_loss=0.038704\n",
      "epoch:  66,    lr=0.000378,    loss=0.039710,    eval_loss=0.038506\n",
      "epoch:  67,    lr=0.000367,    loss=0.039731,    eval_loss=0.038305\n",
      "epoch:  68,    lr=0.000356,    loss=0.039556,    eval_loss=0.038104\n",
      "epoch:  69,    lr=0.000344,    loss=0.039112,    eval_loss=0.037909\n",
      "epoch:  70,    lr=0.000333,    loss=0.039061,    eval_loss=0.037719\n",
      "epoch:  71,    lr=0.000322,    loss=0.038886,    eval_loss=0.037534\n",
      "epoch:  72,    lr=0.000311,    loss=0.038614,    eval_loss=0.037354\n",
      "epoch:  73,    lr=0.000300,    loss=0.038567,    eval_loss=0.037176\n",
      "epoch:  74,    lr=0.000289,    loss=0.038427,    eval_loss=0.037002\n",
      "epoch:  75,    lr=0.000278,    loss=0.038125,    eval_loss=0.036829\n",
      "epoch:  76,    lr=0.000267,    loss=0.037803,    eval_loss=0.036662\n",
      "epoch:  77,    lr=0.000256,    loss=0.037888,    eval_loss=0.036501\n",
      "epoch:  78,    lr=0.000244,    loss=0.037673,    eval_loss=0.036352\n",
      "epoch:  79,    lr=0.000233,    loss=0.037753,    eval_loss=0.036207\n",
      "epoch:  80,    lr=0.000222,    loss=0.037331,    eval_loss=0.036069\n",
      "epoch:  81,    lr=0.000211,    loss=0.037297,    eval_loss=0.035937\n",
      "epoch:  82,    lr=0.000200,    loss=0.036958,    eval_loss=0.035809\n",
      "epoch:  83,    lr=0.000189,    loss=0.037079,    eval_loss=0.035688\n",
      "epoch:  84,    lr=0.000178,    loss=0.037104,    eval_loss=0.035571\n",
      "epoch:  85,    lr=0.000167,    loss=0.036735,    eval_loss=0.035460\n",
      "epoch:  86,    lr=0.000156,    loss=0.036521,    eval_loss=0.035355\n",
      "epoch:  87,    lr=0.000144,    loss=0.036759,    eval_loss=0.035257\n",
      "epoch:  88,    lr=0.000133,    loss=0.036562,    eval_loss=0.035164\n",
      "epoch:  89,    lr=0.000122,    loss=0.036459,    eval_loss=0.035079\n",
      "epoch:  90,    lr=0.000111,    loss=0.036139,    eval_loss=0.035000\n",
      "epoch:  91,    lr=0.000100,    loss=0.036181,    eval_loss=0.034927\n",
      "epoch:  92,    lr=0.000089,    loss=0.036346,    eval_loss=0.034862\n",
      "epoch:  93,    lr=0.000078,    loss=0.036116,    eval_loss=0.034803\n",
      "epoch:  94,    lr=0.000067,    loss=0.035914,    eval_loss=0.034752\n",
      "epoch:  95,    lr=0.000056,    loss=0.036138,    eval_loss=0.034709\n",
      "epoch:  96,    lr=0.000044,    loss=0.035789,    eval_loss=0.034673\n",
      "epoch:  97,    lr=0.000033,    loss=0.036002,    eval_loss=0.034645\n",
      "epoch:  98,    lr=0.000022,    loss=0.035675,    eval_loss=0.034625\n",
      "epoch:  99,    lr=0.000011,    loss=0.035994,    eval_loss=0.034612\n",
      "epoch: 100,    lr=0.000000,    loss=0.035787,    eval_loss=0.034607\n"
     ]
    }
   ],
   "source": [
    "train(train_dataloader, eval_dataloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mldl]",
   "language": "python",
   "name": "conda-env-mldl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
