{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from preprocessing import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2880"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data_repo = os.path.join('.', 'wav_data', 'pretrain')\n",
    "\n",
    "samples_data = glob.glob(os.path.join(sample_data_repo, '**', '*wav'), recursive=True)\n",
    "samples_data = sorted(samples_data)\n",
    "len(samples_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "idx = np.random.permutation(len(samples_data))\n",
    "train_idx = idx[:int(len(samples_data)*0.8)]\n",
    "eval_idx = idx[int(len(samples_data)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = list(np.array(samples_data)[train_idx])\n",
    "eval_samples = list(np.array(samples_data)[eval_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2304, 576)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_samples), len(eval_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2304/2304 [06:41<00:00,  5.74it/s]\n"
     ]
    }
   ],
   "source": [
    "concat_train_tensors = []\n",
    "\n",
    "for data_dir in tqdm(train_samples):\n",
    "    concat_tensor = preprocessing(data_dir, method='mfcc', sr=22050)\n",
    "    concat_train_tensors.append(concat_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14810, 128, 100, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.concatenate(np.array(concat_train_tensors), axis=0)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:40<00:00,  5.76it/s]\n"
     ]
    }
   ],
   "source": [
    "concat_eval_tensors = []\n",
    "\n",
    "for data_dir in tqdm(eval_samples):\n",
    "    concat_tensor = preprocessing(data_dir, method='mfcc', sr=22050)\n",
    "    concat_eval_tensors.append(concat_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3688, 128, 100, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_eval = np.concatenate(np.array(concat_eval_tensors), axis=0)\n",
    "X_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "EPOCHS = 100\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14810, 1, 128, 100]), torch.Size([3688, 1, 128, 100]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.tensor(X_train, device=device).float()\n",
    "X_eval = torch.tensor(X_eval, device=device).float()\n",
    "X_train = X_train.permute(0, 3, 1, 2)\n",
    "X_eval = X_eval.permute(0, 3, 1, 2)\n",
    "\n",
    "X_train.shape, X_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(X_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, drop_last=True)\n",
    "eval_dataloader = DataLoader(X_eval, batch_size=BATCH_SIZE, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 5, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Conv2d(16, 16, 5, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 5, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 32, 5, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, (5, 4), padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = out.reshape(x.shape[0], -1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.conv_trans1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 64, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ConvTranspose2d(64, 64, (5, 4), 2, 0, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        self.conv_trans2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 5, 2, 0, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ConvTranspose2d(32, 32, 5, 1, 0),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32)\n",
    "        )\n",
    "        self.conv_trans3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, 5, 2, 0, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ConvTranspose2d(16, 1, 5, 1, 0),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = x.reshape(x.shape[0], 64, 11, 8)\n",
    "        out = self.conv_trans1(out)\n",
    "        out = self.conv_trans2(out)\n",
    "        out = self.conv_trans3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): AutoEncoder(\n",
       "    (encoder): Encoder(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "        (4): ReLU()\n",
       "        (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "        (4): ReLU()\n",
       "        (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(5, 4), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (conv_trans1): Sequential(\n",
       "        (0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ConvTranspose2d(64, 64, kernel_size=(5, 4), stride=(2, 2), output_padding=(1, 1))\n",
       "        (4): ReLU()\n",
       "        (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_trans2): Sequential(\n",
       "        (0): ConvTranspose2d(64, 32, kernel_size=(5, 5), stride=(2, 2), output_padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ConvTranspose2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "        (4): ReLU()\n",
       "        (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_trans3): Sequential(\n",
       "        (0): ConvTranspose2d(32, 16, kernel_size=(5, 5), stride=(2, 2), output_padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ConvTranspose2d(16, 1, kernel_size=(5, 5), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoEncoder()\n",
    "model = torch.nn.DataParallel(model)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, eval_dataloader, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        # train\n",
    "        train_loss = 0\n",
    "        nb_train_steps = 0\n",
    "\n",
    "        for x_batch in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(x_batch)\n",
    "            \n",
    "            loss = loss_func(outputs, x_batch)\n",
    "            loss.backward()\n",
    "            train_loss += loss.mean().item()\n",
    "            nb_train_steps += 1\n",
    "            \n",
    "            # scheduler.step()\n",
    "            optimizer.step()\n",
    "        \n",
    "        train_loss = train_loss / nb_train_steps\n",
    "             \n",
    "            \n",
    "        # evaluate      \n",
    "        model.eval()\n",
    "        eval_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "        \n",
    "        for x_batch in eval_dataloader:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(x_batch)\n",
    "            \n",
    "            tmp_eval_loss = loss_func(outputs, x_batch)\n",
    "            eval_loss += tmp_eval_loss.mean().item()\n",
    "            nb_eval_steps += 1\n",
    "            \n",
    "        eval_loss = eval_loss / nb_eval_steps\n",
    "            \n",
    "        \n",
    "        for param_group in optimizer.param_groups:\n",
    "            lr = param_group['lr']\n",
    "        print('epoch: {:3d},    lr={:6f},    loss={:5f},    eval_loss={:5f}'\n",
    "              .format(epoch+1, lr, train_loss, eval_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1,    lr=0.001000,    loss=0.086038,    eval_loss=0.030105\n",
      "epoch:   2,    lr=0.001000,    loss=0.024615,    eval_loss=0.028986\n",
      "epoch:   3,    lr=0.001000,    loss=0.023811,    eval_loss=0.028139\n",
      "epoch:   4,    lr=0.001000,    loss=0.023147,    eval_loss=0.027346\n",
      "epoch:   5,    lr=0.001000,    loss=0.022421,    eval_loss=0.026624\n",
      "epoch:   6,    lr=0.001000,    loss=0.021882,    eval_loss=0.026023\n",
      "epoch:   7,    lr=0.001000,    loss=0.021431,    eval_loss=0.025444\n",
      "epoch:   8,    lr=0.001000,    loss=0.020966,    eval_loss=0.024913\n",
      "epoch:   9,    lr=0.001000,    loss=0.020562,    eval_loss=0.024386\n",
      "epoch:  10,    lr=0.001000,    loss=0.020084,    eval_loss=0.023869\n",
      "epoch:  11,    lr=0.001000,    loss=0.019670,    eval_loss=0.023347\n",
      "epoch:  12,    lr=0.001000,    loss=0.019177,    eval_loss=0.022893\n",
      "epoch:  13,    lr=0.001000,    loss=0.018764,    eval_loss=0.022351\n",
      "epoch:  14,    lr=0.001000,    loss=0.018360,    eval_loss=0.021923\n",
      "epoch:  15,    lr=0.001000,    loss=0.018075,    eval_loss=0.021536\n",
      "epoch:  16,    lr=0.001000,    loss=0.017690,    eval_loss=0.021135\n",
      "epoch:  17,    lr=0.001000,    loss=0.017476,    eval_loss=0.020680\n",
      "epoch:  18,    lr=0.001000,    loss=0.016909,    eval_loss=0.019529\n",
      "epoch:  19,    lr=0.001000,    loss=0.014837,    eval_loss=0.015623\n",
      "epoch:  20,    lr=0.001000,    loss=0.012948,    eval_loss=0.014773\n",
      "epoch:  21,    lr=0.001000,    loss=0.011746,    eval_loss=0.013447\n",
      "epoch:  22,    lr=0.001000,    loss=0.011072,    eval_loss=0.012905\n",
      "epoch:  23,    lr=0.001000,    loss=0.010606,    eval_loss=0.012326\n",
      "epoch:  24,    lr=0.001000,    loss=0.010334,    eval_loss=0.012183\n",
      "epoch:  25,    lr=0.001000,    loss=0.009925,    eval_loss=0.011543\n",
      "epoch:  26,    lr=0.001000,    loss=0.009618,    eval_loss=0.011213\n",
      "epoch:  27,    lr=0.001000,    loss=0.009296,    eval_loss=0.010800\n",
      "epoch:  28,    lr=0.001000,    loss=0.008986,    eval_loss=0.010529\n",
      "epoch:  29,    lr=0.001000,    loss=0.008850,    eval_loss=0.010299\n",
      "epoch:  30,    lr=0.001000,    loss=0.008663,    eval_loss=0.010548\n",
      "epoch:  31,    lr=0.001000,    loss=0.008510,    eval_loss=0.009915\n",
      "epoch:  32,    lr=0.001000,    loss=0.008268,    eval_loss=0.009705\n",
      "epoch:  33,    lr=0.001000,    loss=0.008102,    eval_loss=0.009499\n",
      "epoch:  34,    lr=0.001000,    loss=0.007986,    eval_loss=0.009319\n",
      "epoch:  35,    lr=0.001000,    loss=0.007804,    eval_loss=0.009805\n",
      "epoch:  36,    lr=0.001000,    loss=0.007897,    eval_loss=0.009090\n",
      "epoch:  37,    lr=0.001000,    loss=0.007574,    eval_loss=0.008913\n",
      "epoch:  38,    lr=0.001000,    loss=0.007397,    eval_loss=0.008761\n",
      "epoch:  39,    lr=0.001000,    loss=0.007327,    eval_loss=0.008837\n",
      "epoch:  40,    lr=0.001000,    loss=0.007346,    eval_loss=0.008657\n",
      "epoch:  41,    lr=0.001000,    loss=0.007231,    eval_loss=0.008457\n",
      "epoch:  42,    lr=0.001000,    loss=0.007083,    eval_loss=0.008392\n",
      "epoch:  43,    lr=0.001000,    loss=0.007166,    eval_loss=0.008292\n",
      "epoch:  44,    lr=0.001000,    loss=0.006992,    eval_loss=0.008187\n",
      "epoch:  45,    lr=0.001000,    loss=0.006821,    eval_loss=0.008099\n",
      "epoch:  46,    lr=0.001000,    loss=0.006777,    eval_loss=0.008005\n",
      "epoch:  47,    lr=0.001000,    loss=0.006701,    eval_loss=0.007942\n",
      "epoch:  48,    lr=0.001000,    loss=0.006660,    eval_loss=0.007892\n",
      "epoch:  49,    lr=0.001000,    loss=0.006569,    eval_loss=0.007857\n",
      "epoch:  50,    lr=0.001000,    loss=0.006484,    eval_loss=0.007756\n",
      "epoch:  51,    lr=0.001000,    loss=0.006475,    eval_loss=0.007659\n",
      "epoch:  52,    lr=0.001000,    loss=0.006346,    eval_loss=0.007626\n",
      "epoch:  53,    lr=0.001000,    loss=0.006345,    eval_loss=0.007526\n",
      "epoch:  54,    lr=0.001000,    loss=0.006267,    eval_loss=0.007435\n",
      "epoch:  55,    lr=0.001000,    loss=0.006187,    eval_loss=0.007374\n",
      "epoch:  56,    lr=0.001000,    loss=0.006248,    eval_loss=0.007371\n",
      "epoch:  57,    lr=0.001000,    loss=0.006126,    eval_loss=0.007256\n",
      "epoch:  58,    lr=0.001000,    loss=0.006053,    eval_loss=0.007204\n",
      "epoch:  59,    lr=0.001000,    loss=0.005960,    eval_loss=0.007187\n",
      "epoch:  60,    lr=0.001000,    loss=0.005954,    eval_loss=0.007085\n",
      "epoch:  61,    lr=0.001000,    loss=0.005894,    eval_loss=0.007022\n",
      "epoch:  62,    lr=0.001000,    loss=0.005917,    eval_loss=0.006981\n",
      "epoch:  63,    lr=0.001000,    loss=0.005794,    eval_loss=0.006897\n",
      "epoch:  64,    lr=0.001000,    loss=0.005834,    eval_loss=0.006926\n",
      "epoch:  65,    lr=0.001000,    loss=0.005758,    eval_loss=0.006836\n",
      "epoch:  66,    lr=0.001000,    loss=0.005703,    eval_loss=0.006831\n",
      "epoch:  67,    lr=0.001000,    loss=0.005756,    eval_loss=0.006785\n",
      "epoch:  68,    lr=0.001000,    loss=0.005686,    eval_loss=0.006723\n",
      "epoch:  69,    lr=0.001000,    loss=0.005586,    eval_loss=0.006670\n",
      "epoch:  70,    lr=0.001000,    loss=0.005542,    eval_loss=0.006619\n",
      "epoch:  71,    lr=0.001000,    loss=0.005549,    eval_loss=0.006580\n",
      "epoch:  72,    lr=0.001000,    loss=0.005494,    eval_loss=0.006563\n",
      "epoch:  73,    lr=0.001000,    loss=0.005449,    eval_loss=0.006521\n",
      "epoch:  74,    lr=0.001000,    loss=0.005413,    eval_loss=0.006451\n",
      "epoch:  75,    lr=0.001000,    loss=0.005416,    eval_loss=0.006487\n",
      "epoch:  76,    lr=0.001000,    loss=0.005373,    eval_loss=0.006491\n",
      "epoch:  77,    lr=0.001000,    loss=0.005376,    eval_loss=0.006426\n",
      "epoch:  78,    lr=0.001000,    loss=0.005287,    eval_loss=0.006355\n",
      "epoch:  79,    lr=0.001000,    loss=0.005317,    eval_loss=0.006332\n",
      "epoch:  80,    lr=0.001000,    loss=0.005372,    eval_loss=0.006298\n",
      "epoch:  81,    lr=0.001000,    loss=0.005226,    eval_loss=0.006222\n",
      "epoch:  82,    lr=0.001000,    loss=0.005186,    eval_loss=0.006240\n",
      "epoch:  83,    lr=0.001000,    loss=0.005204,    eval_loss=0.006276\n",
      "epoch:  84,    lr=0.001000,    loss=0.005176,    eval_loss=0.006167\n",
      "epoch:  85,    lr=0.001000,    loss=0.005133,    eval_loss=0.006112\n",
      "epoch:  86,    lr=0.001000,    loss=0.005114,    eval_loss=0.006113\n",
      "epoch:  87,    lr=0.001000,    loss=0.005111,    eval_loss=0.006117\n",
      "epoch:  88,    lr=0.001000,    loss=0.005077,    eval_loss=0.006126\n",
      "epoch:  89,    lr=0.001000,    loss=0.005021,    eval_loss=0.006161\n",
      "epoch:  90,    lr=0.001000,    loss=0.005115,    eval_loss=0.006311\n",
      "epoch:  91,    lr=0.001000,    loss=0.005075,    eval_loss=0.006021\n",
      "epoch:  92,    lr=0.001000,    loss=0.004961,    eval_loss=0.005949\n",
      "epoch:  93,    lr=0.001000,    loss=0.004938,    eval_loss=0.005962\n",
      "epoch:  94,    lr=0.001000,    loss=0.004968,    eval_loss=0.005966\n",
      "epoch:  95,    lr=0.001000,    loss=0.004913,    eval_loss=0.005876\n",
      "epoch:  96,    lr=0.001000,    loss=0.004874,    eval_loss=0.005924\n",
      "epoch:  97,    lr=0.001000,    loss=0.004844,    eval_loss=0.005806\n",
      "epoch:  98,    lr=0.001000,    loss=0.004819,    eval_loss=0.005755\n",
      "epoch:  99,    lr=0.001000,    loss=0.004784,    eval_loss=0.005809\n",
      "epoch: 100,    lr=0.001000,    loss=0.004859,    eval_loss=0.005925\n"
     ]
    }
   ],
   "source": [
    "train(train_dataloader, eval_dataloader, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mldl]",
   "language": "python",
   "name": "conda-env-mldl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
