{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from preprocessing import preprocessing, convert_spectrograms, convert_tensor\n",
    "from model_ae import Encoder\n",
    "from utils.optimization import WarmupLinearSchedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, num_attn_heads, attn_hidden_size, dropout_prob, with_focus_attn):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        self.num_attn_heads = num_attn_heads\n",
    "        self.hidden_size = attn_hidden_size\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.with_focus_attn = with_focus_attn\n",
    "        \n",
    "        self.attn_head_size = int(self.hidden_size / self.num_attn_heads)\n",
    "        self.all_head_size = self.num_attn_heads * self.attn_head_size\n",
    "\n",
    "        self.query = nn.Linear(self.hidden_size, self.all_head_size)\n",
    "        self.key = nn.Linear(self.hidden_size, self.all_head_size)\n",
    "        self.value = nn.Linear(self.hidden_size, self.all_head_size)\n",
    "\n",
    "        self.o_proj = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_prob)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "        if(with_focus_attn == True):\n",
    "            self.tanh = nn.Tanh()\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "            \n",
    "            self.linear_focus_query = nn.Linear(num_attn_heads * self.attn_head_size, \n",
    "                                                num_attn_heads * self.attn_head_size)\n",
    "            self.linear_focus_global = nn.Linear(num_attn_heads * self.attn_head_size, \n",
    "                                                 num_attn_heads * self.attn_head_size)\n",
    "            \n",
    "            up = torch.randn(num_attn_heads, 1, self.attn_head_size)\n",
    "            self.up = Variable(up, requires_grad=True).cuda()\n",
    "            torch.nn.init.xavier_uniform_(self.up)\n",
    "            \n",
    "            uz = torch.randn(num_attn_heads, 1, self.attn_head_size)\n",
    "            self.uz = Variable(uz, requires_grad=True).cuda()\n",
    "            torch.nn.init.xavier_uniform_(self.uz)\n",
    "\n",
    "    def transpose_for_scores(self, x):\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attn_heads, self.attn_head_size)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        key_len = hidden_states.size(1)\n",
    "        \n",
    "        mixed_query_layer = self.query(hidden_states)\n",
    "        mixed_key_layer = self.key(hidden_states)\n",
    "        mixed_value_layer = self.value(hidden_states)\n",
    "        \n",
    "        if(self.with_focus_attn == True):\n",
    "            glo = torch.mean(mixed_query_layer, dim=1, keepdim=True)\n",
    "            \n",
    "            c = self.tanh(self.linear_focus_query(mixed_query_layer) + self.linear_focus_global(glo))\n",
    "            c = self.transpose_for_scores(c)\n",
    "            \n",
    "            p = c * self.up\n",
    "            p = p.sum(3).squeeze()\n",
    "            z = c * self.uz\n",
    "            z = z.sum(3).squeeze()\n",
    "            \n",
    "            P = self.sigmoid(p) * key_len\n",
    "            Z = self.sigmoid(z) * key_len\n",
    "            \n",
    "            j = torch.arange(start=0, end=key_len, dtype=P.dtype).unsqueeze(0).unsqueeze(0).unsqueeze(0).to('cuda')\n",
    "            P = P.unsqueeze(-1)\n",
    "            Z = Z.unsqueeze(-1)\n",
    "            \n",
    "            G = -(j - P)**2 * 2 / (Z**2)\n",
    "\n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
    "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
    "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
    "\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "        attention_scores = attention_scores / math.sqrt(self.attn_head_size)\n",
    "        \n",
    "        if(self.with_focus_attn == True):\n",
    "            attention_scores = attention_scores + G\n",
    "            \n",
    "        attention_probs = self.softmax(attention_scores)\n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)\n",
    "        attention_output = self.o_proj(context_layer)\n",
    "\n",
    "        return attention_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLDNN(nn.Module):\n",
    "    def __init__(self, conv_dim, checkpoint=None, hidden_size=64, num_layers=2,\n",
    "                 bidirectional=True, with_focus_attn=False):\n",
    "        super(CLDNN, self).__init__()\n",
    "        self.conv_dim = conv_dim\n",
    "        if(conv_dim == '1d'):\n",
    "            self.encoder = Encoder(conv_dim)\n",
    "            if checkpoint:\n",
    "                self.encoder.load_state_dict(torch.load(checkpoint))\n",
    "            self.attn = MultiHeadedAttention(num_attn_heads=4, attn_hidden_size=8, dropout_prob=0.1,\n",
    "                                             with_focus_attn=with_focus_attn)\n",
    "            self.lstm = nn.LSTM(8, hidden_size=hidden_size, num_layers=num_layers, bidirectional=bidirectional)\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(hidden_size*2 if bidirectional else hidden_size, 8),\n",
    "            )\n",
    "        elif(conv_dim == '2d'):\n",
    "            self.encoder = Encoder(conv_dim)\n",
    "            if checkpoint:\n",
    "                self.encoder.load_state_dict(torch.load(checkpoint))\n",
    "            self.attn = MultiHeadedAttention(num_attn_heads=4, attn_hidden_size=176, dropout_prob=0.1, \n",
    "                                             with_focus_attn=with_focus_attn)\n",
    "            self.gap = nn.AdaptiveAvgPool2d((1, 11))\n",
    "            self.lstm = nn.LSTM(11, hidden_size=hidden_size, num_layers=num_layers, bidirectional=bidirectional)\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(hidden_size*2 if bidirectional else hidden_size, 8),\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Convolution dimension not found: %s\" % (conv_dim))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        if(self.conv_dim == '1d'):\n",
    "            out = self.encoder(x)  # (batch, 1, 40, 100) -> (batch, 8, 1, 100)\n",
    "            out = torch.squeeze(out, 2)  # (batch, 8, 1, 100) -> (batch, 8, 100)\n",
    "            out = out.permute(0, 2, 1)  # (batch, 8, 100) -> (batch, 100, 8)\n",
    "            h = out\n",
    "            out = self.attn(out)  # (batch, 100, 8) -> (batch, 100, 8)\n",
    "            out = h + out\n",
    "            out = out.permute(1, 0, 2)  # (batch, 100, 8) -> (100, batch, 8)\n",
    "            self.lstm.flatten_parameters()\n",
    "            out, _ = self.lstm(out)  # (100, batch, 8) -> (100, batch, num_directions*hidden_size)\n",
    "            out = out[-1]  # (100, batch, num_directions*hidden_size) -> (batch, num_directions*hidden_size)\n",
    "            out = self.fc(out)  # (batch, num_directions*hidden_size) -> (batch, 1)\n",
    "        elif(self.conv_dim == '2d'):\n",
    "            out = self.encoder(x)  # (batch, 1, 128, 100) -> (batch, 16, 11, 8)\n",
    "            out = out.permute(0, 3, 1, 2)  # (batch, 16, 11, 8) -> (batch, 8, 16, 11)\n",
    "            h = out\n",
    "            new_out_shape = out.size()[:2] + (out.size()[2] * out.size()[3],)\n",
    "            out = out.view(*new_out_shape)  # (batch, 8, 16, 11) -> (batch, 8, 176)\n",
    "            out = self.attn(out)  # (batch, 8, 176) -> (batch, 8, 176)\n",
    "            out = out.view(h.size())  # (batch, 8, 176) -> (batch, 8, 16, 11)\n",
    "            out = h + out\n",
    "            out = self.gap(out)  # (batch, 8, 16, 11) -> (batch, 8, 1, 11)\n",
    "            out = torch.squeeze(out, 2)  # (batch, 8, 1, 11) -> (batch, 8, 11)\n",
    "            out = out.permute(1, 0, 2)  # (batch, 8, 11) -> (8, batch, 11)\n",
    "            self.lstm.flatten_parameters()\n",
    "            out, _ = self.lstm(out)  # (8, batch, 11) -> (8, batch, num_directions*hidden_size)\n",
    "            out = out[-1]  # (8, batch, num_directions*hidden_size) -> (batch, num_directions*hidden_size)\n",
    "            out = self.fc(out)  # (batch, num_directions*hidden_size) -> (batch, 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLDNN_G(nn.Module):\n",
    "    def __init__(self, conv_dim, checkpoint=None, hidden_size=64, num_layers=2,\n",
    "                 bidirectional=True, with_focus_attn=False):\n",
    "        super(CLDNN_G, self).__init__()\n",
    "        self.conv_dim = conv_dim\n",
    "        if(conv_dim == '1d'):\n",
    "            self.encoder = Encoder(conv_dim)\n",
    "            if checkpoint:\n",
    "                self.encoder.load_state_dict(torch.load(checkpoint))\n",
    "            self.attn = MultiHeadedAttention(num_attn_heads=4, attn_hidden_size=8, dropout_prob=0.1,\n",
    "                                             with_focus_attn=with_focus_attn)\n",
    "            self.lstm = nn.LSTM(8, hidden_size=hidden_size, num_layers=num_layers, bidirectional=bidirectional)\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(hidden_size*2 if bidirectional else hidden_size, 1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        elif(conv_dim == '2d'):\n",
    "            self.encoder = Encoder(conv_dim)\n",
    "            if checkpoint:\n",
    "                self.encoder.load_state_dict(torch.load(checkpoint))\n",
    "            self.attn = MultiHeadedAttention(num_attn_heads=4, attn_hidden_size=176, dropout_prob=0.1, \n",
    "                                             with_focus_attn=with_focus_attn)\n",
    "            self.gap = nn.AdaptiveAvgPool2d((1, 11))\n",
    "            self.lstm = nn.LSTM(11, hidden_size=hidden_size, num_layers=num_layers, bidirectional=bidirectional)\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(hidden_size*2 if bidirectional else hidden_size, 1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Convolution dimension not found: %s\" % (conv_dim))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        if(self.conv_dim == '1d'):\n",
    "            out = self.encoder(x)  # (batch, 1, 40, 100) -> (batch, 8, 1, 100)\n",
    "            out = torch.squeeze(out, 2)  # (batch, 8, 1, 100) -> (batch, 8, 100)\n",
    "            out = out.permute(0, 2, 1)  # (batch, 8, 100) -> (batch, 100, 8)\n",
    "            h = out\n",
    "            out = self.attn(out)  # (batch, 100, 8) -> (batch, 100, 8)\n",
    "            out = h + out\n",
    "            out = out.permute(1, 0, 2)  # (batch, 100, 8) -> (100, batch, 8)\n",
    "            self.lstm.flatten_parameters()\n",
    "            out, _ = self.lstm(out)  # (100, batch, 8) -> (100, batch, num_directions*hidden_size)\n",
    "            out = out[-1]  # (100, batch, num_directions*hidden_size) -> (batch, num_directions*hidden_size)\n",
    "            out = self.fc(out)  # (batch, num_directions*hidden_size) -> (batch, 1)\n",
    "        elif(self.conv_dim == '2d'):\n",
    "            out = self.encoder(x)  # (batch, 1, 128, 100) -> (batch, 16, 11, 8)\n",
    "            out = out.permute(0, 3, 1, 2)  # (batch, 16, 11, 8) -> (batch, 8, 16, 11)\n",
    "            h = out\n",
    "            new_out_shape = out.size()[:2] + (out.size()[2] * out.size()[3],)\n",
    "            out = out.view(*new_out_shape)  # (batch, 8, 16, 11) -> (batch, 8, 176)\n",
    "            out = self.attn(out)  # (batch, 8, 176) -> (batch, 8, 176)\n",
    "            out = out.view(h.size())  # (batch, 8, 176) -> (batch, 8, 16, 11)\n",
    "            out = h + out\n",
    "            out = self.gap(out)  # (batch, 8, 16, 11) -> (batch, 8, 1, 11)\n",
    "            out = torch.squeeze(out, 2)  # (batch, 8, 1, 11) -> (batch, 8, 11)\n",
    "            out = out.permute(1, 0, 2)  # (batch, 8, 11) -> (8, batch, 11)\n",
    "            self.lstm.flatten_parameters()\n",
    "            out, _ = self.lstm(out)  # (8, batch, 11) -> (8, batch, num_directions*hidden_size)\n",
    "            out = out[-1]  # (8, batch, num_directions*hidden_size) -> (batch, num_directions*hidden_size)\n",
    "            out = self.fc(out)  # (batch, num_directions*hidden_size) -> (batch, 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, eval_dataloader, epochs):\n",
    "        #print('Start training')\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            nb_train_steps = 0\n",
    "            correct = 0\n",
    "            num_samples = 0\n",
    "            \n",
    "            if(multi_task == 'true'):\n",
    "                for X_batch, y_batch, y_g_batch in train_dataloader:\n",
    "                    X_batch = X_batch.to(device)\n",
    "                    y_batch = y_batch.to(device)\n",
    "                    y_g_batch = y_g_batch.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    outputs = model(X_batch)\n",
    "                    outputs_g = model_g(X_batch)\n",
    "\n",
    "                    loss_1 = loss_func(outputs, y_batch)\n",
    "                    loss_2 = loss_func_g(outputs_g, y_g_batch)\n",
    "                    loss = loss_1 + 0.8 * loss_2\n",
    "                    loss.backward(retain_graph=True)\n",
    "\n",
    "                    optimizer.step()\n",
    "                    opt_scheduler.step()\n",
    "\n",
    "                    train_loss += loss.mean().item()\n",
    "                    nb_train_steps += 1\n",
    "\n",
    "                    outputs = softmax(outputs)\n",
    "                    outputs = torch.argmax(outputs, dim=1)\n",
    "                    correct += (outputs == y_batch).float().sum()\n",
    "                    num_samples += len(X_batch)\n",
    "\n",
    "                train_loss = train_loss / nb_train_steps\n",
    "                train_accuracy = correct / num_samples\n",
    "\n",
    "                model.eval()\n",
    "                eval_loss = 0\n",
    "                nb_eval_steps = 0\n",
    "                correct = 0\n",
    "                num_samples = 0\n",
    "\n",
    "                for X_batch, y_batch, y_g_batch in eval_dataloader:\n",
    "                    X_batch = X_batch.to(device)\n",
    "                    y_batch = y_batch.to(device)\n",
    "                    y_g_batch = y_g_batch.to(device)\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(X_batch)\n",
    "                        outputs_g = model_g(X_batch)\n",
    "\n",
    "                    tmp_eval_loss_1 = loss_func(outputs, y_batch)\n",
    "                    tmp_eval_loss_2 = loss_func_g(outputs_g, y_g_batch)\n",
    "                    tmp_eval_loss = tmp_eval_loss_1 + 0.8 * tmp_eval_loss_2\n",
    "                    eval_loss += tmp_eval_loss.mean().item()\n",
    "                    nb_eval_steps += 1\n",
    "\n",
    "                    outputs = softmax(outputs)\n",
    "                    outputs = torch.argmax(outputs, dim=1)\n",
    "                    correct += (outputs == y_batch).float().sum()\n",
    "                    num_samples += len(X_batch)\n",
    "\n",
    "                eval_loss = eval_loss / nb_eval_steps\n",
    "                eval_accuracy = correct / num_samples\n",
    "            else:\n",
    "                for X_batch, y_batch in train_dataloader:\n",
    "                    X_batch = X_batch.to(device)\n",
    "                    y_batch = y_batch.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    outputs = model(X_batch)\n",
    "\n",
    "                    loss = loss_func(outputs, y_batch)\n",
    "                    loss.backward()\n",
    "\n",
    "                    optimizer.step()\n",
    "                    opt_scheduler.step()\n",
    "\n",
    "                    train_loss += loss.mean().item()\n",
    "                    nb_train_steps += 1\n",
    "\n",
    "                    outputs = softmax(outputs)\n",
    "                    outputs = torch.argmax(outputs, dim=1)\n",
    "                    correct += (outputs == y_batch).float().sum()\n",
    "                    num_samples += len(X_batch)\n",
    "\n",
    "                train_loss = train_loss / nb_train_steps\n",
    "                train_accuracy = correct / num_samples\n",
    "\n",
    "                model.eval()\n",
    "                eval_loss = 0\n",
    "                nb_eval_steps = 0\n",
    "                correct = 0\n",
    "                num_samples = 0\n",
    "\n",
    "                for X_batch, y_batch in eval_dataloader:\n",
    "                    X_batch = X_batch.to(device)\n",
    "                    y_batch = y_batch.to(device)\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(X_batch)\n",
    "\n",
    "                    tmp_eval_loss = loss_func(outputs, y_batch)\n",
    "                    eval_loss += tmp_eval_loss.mean().item()\n",
    "                    nb_eval_steps += 1\n",
    "\n",
    "                    outputs = softmax(outputs)\n",
    "                    outputs = torch.argmax(outputs, dim=1)\n",
    "                    correct += (outputs == y_batch).float().sum()\n",
    "                    num_samples += len(X_batch)\n",
    "\n",
    "                eval_loss = eval_loss / nb_eval_steps\n",
    "                eval_accuracy = correct / num_samples\n",
    "            '''\n",
    "            for param_group in optimizer.param_groups:\n",
    "                lr = param_group['lr']\n",
    "            print('epoch: {:3d},    lr={:6f},    loss={:5f},    train_acc={:5f},    eval_loss={:5f},    eval_acc={:5f}'\n",
    "                  .format(epoch+1, lr, train_loss, train_accuracy, eval_loss, eval_accuracy))\n",
    "\n",
    "            \n",
    "            if((epoch+1) % args.save_checkpoint_steps == 0):\n",
    "                model_checkpoint = \"%s_%s_step_%d.pt\" % ('CLDNN', args.conv_dim, epoch+1)\n",
    "                output_model_file = os.path.join(args.output_dir, model_checkpoint)\n",
    "                if(args.multi_gpu == 'true'):\n",
    "                    torch.save(model.module.state_dict(), output_model_file)\n",
    "                else:\n",
    "                    torch.save(model.state_dict(), output_model_file)\n",
    "                print(\"Saving checkpoint %s\" % output_model_file)\n",
    "            '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_dim_list = ['1d']\n",
    "augmentation_list = ['true', 'false']\n",
    "focus_attn_list = [True, False]\n",
    "multi_task_list = ['true', 'false']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1080it [00:07, 152.71it/s]\n",
      "360it [00:01, 195.04it/s]\n",
      "1080it [00:06, 179.13it/s]\n",
      "360it [00:01, 188.43it/s]\n",
      "1080it [00:05, 192.41it/s]\n",
      "360it [00:01, 199.83it/s]\n",
      "1080it [00:05, 194.11it/s]\n",
      "360it [00:01, 198.00it/s]\n",
      "1080it [00:05, 188.87it/s]\n",
      "360it [00:02, 134.73it/s]\n",
      "1080it [00:06, 157.84it/s]\n",
      "360it [00:01, 198.79it/s]\n",
      "1080it [00:05, 195.13it/s]\n",
      "360it [00:01, 194.85it/s]\n",
      "1080it [00:07, 136.18it/s]\n",
      "360it [00:02, 138.39it/s]\n",
      "1080it [00:06, 174.14it/s]\n",
      "360it [00:01, 198.55it/s]\n",
      "1080it [00:05, 186.11it/s]\n",
      "360it [00:01, 186.41it/s]\n",
      "20it [00:00, 195.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_dim: 1d \taugmentation true \twith_focus_attn: True \tmulti_task: true\n",
      "Test accuray: 0.66444\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1080it [00:05, 184.54it/s]\n",
      "360it [00:02, 138.25it/s]\n",
      "1080it [00:06, 170.93it/s]\n",
      "360it [00:01, 194.46it/s]\n",
      "1080it [00:05, 184.99it/s]\n",
      "360it [00:02, 140.23it/s]\n",
      "1080it [00:05, 194.14it/s]\n",
      "360it [00:01, 196.27it/s]\n",
      "1080it [00:05, 195.47it/s]\n",
      "360it [00:01, 199.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# AI Hub\n",
    "for conv_dim in conv_dim_list:\n",
    "    for augmentation in augmentation_list:\n",
    "        for with_focus_attn in focus_attn_list:\n",
    "            for multi_task in multi_task_list:\n",
    "                #conv_dim = '1d'\n",
    "                checkpoint = './output/aae_' + conv_dim + '_step_300.pt'\n",
    "                hidden_size = 128\n",
    "                num_layers = 2\n",
    "                bidirectional = 'true'\n",
    "                #with_focus_attn = 'false'\n",
    "\n",
    "                batch_size = 128\n",
    "                num_epochs = 300\n",
    "                learning_rate = 0.0001\n",
    "\n",
    "                use_warmup = 'true'\n",
    "                data_dir = './wav_data/pretrain/RAVDESS_resample/'\n",
    "                #multi_task = 'false'\n",
    "                #augmentation = 'true'\n",
    "\n",
    "                bidirectional = True if(bidirectional == 'true') else False\n",
    "                #with_focus_attn = True if(with_focus_attn == 'true') else False\n",
    "                n_mfcc = 40 if(conv_dim == '1d') else 128\n",
    "\n",
    "                device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "                sample_datas = glob.glob(os.path.join(data_dir, '**', '*wav'), recursive=True)\n",
    "                sample_datas = sorted(sample_datas)\n",
    "\n",
    "                acc_list = []\n",
    "                for i in range(5):\n",
    "                    np.random.seed(10 * i + 3)\n",
    "                    idx = np.random.permutation(len(sample_datas))\n",
    "                    train_idx = idx[:int(len(sample_datas)*0.75)]\n",
    "                    eval_idx = idx[int(len(sample_datas)*0.75):]\n",
    "\n",
    "                    train_samples = list(np.array(sample_datas)[train_idx])\n",
    "                    eval_samples = list(np.array(sample_datas)[eval_idx])\n",
    "\n",
    "                    y = np.array(list(map(lambda x: int(x.split('/')[-1].split('-')[2]) - 1, sample_datas)))\n",
    "                    y_train = y[train_idx]\n",
    "                    y_eval = y[eval_idx]\n",
    "\n",
    "                    if(multi_task == 'true'):\n",
    "                        speaker = np.array(list(map(lambda x: int(x.split('/')[-1].split('-')[-1].split('.')[0]), sample_datas)))\n",
    "                        y_gender = np.array(list(map(lambda x: 1 if x % 2 ==0 else 0, speaker)))\n",
    "\n",
    "                        y_g_train = y_gender[train_idx]\n",
    "                        y_g_eval = y_gender[eval_idx]\n",
    "\n",
    "                    X_train, y_train = convert_spectrograms(train_samples, conv_dim=conv_dim, sr=16000, labels=y_train)\n",
    "                    X_eval, y_eval = convert_spectrograms(eval_samples, conv_dim=conv_dim, sr=16000, labels=y_eval)\n",
    "\n",
    "                    if(augmentation == 'true'):\n",
    "                        X_train_flip = X_train[:, :, :, ::-1]\n",
    "                        y_train_flip = y_train.copy()\n",
    "\n",
    "                        X_train = np.concatenate((X_train, X_train_flip), axis=0)\n",
    "                        y_train = np.concatenate((y_train, y_train_flip), axis=0)\n",
    "                    \n",
    "                    X_train, y_train = convert_tensor(X_train, y_train)\n",
    "                    X_eval, y_eval = convert_tensor(X_eval, y_eval)\n",
    "\n",
    "                    y_train = y_train.long()\n",
    "                    y_eval = y_eval.long()\n",
    "\n",
    "                    if(multi_task == 'true'):\n",
    "                        _, y_g_train = convert_spectrograms(train_samples, conv_dim=conv_dim, sr=16000, labels=y_g_train)\n",
    "                        _, y_g_eval = convert_spectrograms(eval_samples, conv_dim=conv_dim, sr=16000, labels=y_g_eval)\n",
    "\n",
    "                        if(augmentation == 'true'):\n",
    "                            y_g_train_flip = y_g_train.copy()\n",
    "                            y_g_train = np.concatenate((y_g_train, y_g_train_flip))\n",
    "                        \n",
    "                        y_g_train = torch.tensor(y_g_train).float()\n",
    "                        y_g_eval = torch.tensor(y_g_eval).float()\n",
    "\n",
    "                        y_g_train = y_g_train.unsqueeze(-1)\n",
    "                        y_g_eval = y_g_eval.unsqueeze(-1)\n",
    "\n",
    "                    if(multi_task == 'true'):\n",
    "                        train_ds = TensorDataset(X_train, y_train, y_g_train)\n",
    "                        eval_ds = TensorDataset(X_eval, y_eval, y_g_eval)\n",
    "                    else:\n",
    "                        train_ds = TensorDataset(X_train, y_train)\n",
    "                        eval_ds = TensorDataset(X_eval, y_eval)\n",
    "\n",
    "                    train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)\n",
    "                    eval_dataloader = DataLoader(eval_ds, batch_size=batch_size, num_workers=0, drop_last=True)\n",
    "\n",
    "                    model = CLDNN(conv_dim=conv_dim, checkpoint=checkpoint, hidden_size=hidden_size,\n",
    "                                  num_layers=num_layers, bidirectional=bidirectional,\n",
    "                                  with_focus_attn=with_focus_attn).to(device)\n",
    "\n",
    "                    if(multi_task == 'true'):\n",
    "                        model_g = CLDNN_G(conv_dim=conv_dim, checkpoint=checkpoint, hidden_size=hidden_size,\n",
    "                                            num_layers=num_layers, bidirectional=bidirectional,\n",
    "                                            with_focus_attn=with_focus_attn).to(device)\n",
    "\n",
    "                    if(multi_task == 'true'):\n",
    "                        loss_func = nn.CrossEntropyLoss()\n",
    "                        loss_func_g = nn.BCELoss()\n",
    "                        optimizer = optim.Adam(list(model.parameters()) + list(model_g.parameters()), lr=learning_rate)\n",
    "                    else:\n",
    "                        loss_func = nn.CrossEntropyLoss()\n",
    "                        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "                    if(use_warmup == 'true'):\n",
    "                        t_total = len(train_dataloader) // 1 * num_epochs\n",
    "                        opt_scheduler = WarmupLinearSchedule(optimizer, warmup_steps=t_total * 0.1, t_total=t_total)\n",
    "\n",
    "                    train(train_dataloader, eval_dataloader, num_epochs)\n",
    "\n",
    "                    model.eval()\n",
    "                    if(multi_task == 'true'):\n",
    "                        model_g.eval()\n",
    "\n",
    "                    correct = 0\n",
    "                    n = 0\n",
    "                    for i in range(len(eval_samples)):\n",
    "                        try:\n",
    "                            X_new = preprocessing(eval_samples[i], method='mfcc', sr=16000, n_mfcc=n_mfcc)\n",
    "                            X_new = convert_tensor(X_new).to(device)\n",
    "                            y_new = model(X_new)\n",
    "                            y_new = torch.argmax(nn.Softmax(dim=-1)(torch.mean(y_new, dim=0)))\n",
    "                            #y_new = sorted(dict(collections.Counter(torch.argmax(nn.Softmax(dim=-1)(y_new), dim=1).cpu().numpy()))\n",
    "                            #               .items(), key=(lambda x: x[1]), reverse=True)[0][0]\n",
    "                            y_new = 1 if (y_new.item() == y[eval_idx][i].item()) else 0\n",
    "                            correct += y_new\n",
    "                            n += 1\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                    acc = correct / n\n",
    "                    acc_list.append(acc)\n",
    "\n",
    "                acc_mean = sum(acc_list) / 5\n",
    "                print('conv_dim:', conv_dim, '\\taugmentation', augmentation, \n",
    "                      '\\twith_focus_attn:', with_focus_attn, '\\tmulti_task:', multi_task)\n",
    "                print('Test accuray:', round(acc_mean, 5))\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1080it [00:07, 152.07it/s]\n",
      "360it [00:02, 135.77it/s]\n",
      "1080it [00:07, 145.02it/s]\n",
      "360it [00:02, 179.74it/s]\n",
      "1080it [00:07, 138.82it/s]\n",
      "360it [00:02, 148.03it/s]\n",
      "1080it [00:08, 132.02it/s]\n",
      "360it [00:02, 132.90it/s]\n",
      "1080it [00:05, 191.33it/s]\n",
      "360it [00:02, 170.37it/s]\n",
      "1080it [00:06, 168.55it/s]\n",
      "360it [00:01, 192.66it/s]\n",
      "1080it [00:06, 173.92it/s]\n",
      "360it [00:01, 187.85it/s]\n",
      "1080it [00:05, 187.68it/s]\n",
      "360it [00:01, 187.75it/s]\n",
      "1080it [00:09, 119.01it/s]\n",
      "360it [00:02, 161.21it/s]\n",
      "1080it [00:05, 187.06it/s]\n",
      "360it [00:01, 184.49it/s]\n",
      "14it [00:00, 135.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_dim: 1d \taugmentation true \twith_focus_attn: True \tmulti_task: true\n",
      "Test accuray: 0.65833\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1080it [00:07, 143.31it/s]\n",
      "360it [00:02, 136.37it/s]\n",
      "1080it [00:07, 140.99it/s]\n",
      "360it [00:02, 136.69it/s]\n",
      "1080it [00:06, 160.39it/s]\n",
      "360it [00:02, 134.02it/s]\n",
      "1080it [00:05, 195.86it/s]\n",
      "360it [00:01, 196.55it/s]\n",
      "1080it [00:05, 192.06it/s]\n",
      "360it [00:01, 191.59it/s]\n",
      "20it [00:00, 195.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_dim: 1d \taugmentation true \twith_focus_attn: True \tmulti_task: false\n",
      "Test accuray: 0.635\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1080it [00:06, 177.41it/s]\n",
      "360it [00:01, 189.22it/s]\n",
      "1080it [00:05, 189.18it/s]\n",
      "360it [00:01, 195.85it/s]\n",
      "1080it [00:08, 127.91it/s]\n",
      "360it [00:02, 160.11it/s]\n",
      "1080it [00:07, 140.40it/s]\n",
      "360it [00:02, 121.80it/s]\n",
      "1080it [00:06, 170.81it/s]\n",
      "360it [00:02, 174.91it/s]\n",
      "1080it [00:05, 186.47it/s]\n",
      "360it [00:01, 188.32it/s]\n",
      "1080it [00:05, 180.82it/s]\n",
      "360it [00:01, 195.41it/s]\n",
      "1080it [00:05, 190.79it/s]\n",
      "360it [00:01, 195.58it/s]\n",
      "1080it [00:05, 180.70it/s]\n",
      "360it [00:01, 198.38it/s]\n",
      "1080it [00:06, 175.51it/s]\n",
      "360it [00:02, 134.51it/s]\n",
      "19it [00:00, 186.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_dim: 1d \taugmentation true \twith_focus_attn: False \tmulti_task: true\n",
      "Test accuray: 0.66556\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1080it [00:06, 162.71it/s]\n",
      "360it [00:02, 135.80it/s]\n",
      "1080it [00:06, 168.54it/s]\n",
      "360it [00:02, 136.04it/s]\n",
      "1080it [00:07, 136.51it/s]\n",
      "360it [00:02, 143.10it/s]\n",
      "1080it [00:07, 151.91it/s]\n",
      "360it [00:02, 155.34it/s]\n",
      "1080it [00:05, 196.49it/s]\n",
      "360it [00:01, 197.73it/s]\n",
      "20it [00:00, 194.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_dim: 1d \taugmentation true \twith_focus_attn: False \tmulti_task: false\n",
      "Test accuray: 0.63722\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1080it [00:07, 138.60it/s]\n",
      "360it [00:02, 137.13it/s]\n",
      "1080it [00:07, 135.88it/s]\n",
      "360it [00:02, 137.08it/s]\n",
      "1080it [00:05, 195.76it/s]\n",
      "360it [00:01, 195.37it/s]\n",
      "1080it [00:05, 191.76it/s]\n",
      "360it [00:01, 192.06it/s]\n",
      "1080it [00:08, 134.77it/s]\n",
      "360it [00:02, 134.27it/s]\n",
      "1080it [00:08, 133.57it/s]\n",
      "360it [00:02, 146.71it/s]\n",
      "1080it [00:05, 184.18it/s]\n",
      "360it [00:02, 173.07it/s]\n",
      "1080it [00:06, 159.87it/s]\n",
      "360it [00:02, 136.24it/s]\n",
      "1080it [00:05, 196.70it/s]\n",
      "360it [00:01, 194.51it/s]\n",
      "1080it [00:06, 168.51it/s]\n",
      "360it [00:02, 137.40it/s]\n",
      "20it [00:00, 190.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_dim: 1d \taugmentation false \twith_focus_attn: True \tmulti_task: true\n",
      "Test accuray: 0.55667\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1080it [00:05, 189.00it/s]\n",
      "360it [00:01, 192.38it/s]\n",
      "1080it [00:07, 146.52it/s]\n",
      "360it [00:02, 179.53it/s]\n",
      "1080it [00:07, 143.40it/s]\n",
      "360it [00:02, 136.78it/s]\n",
      "1080it [00:06, 173.32it/s]\n",
      "360it [00:02, 137.28it/s]\n",
      "1080it [00:05, 188.31it/s]\n",
      "360it [00:02, 177.87it/s]\n",
      "20it [00:00, 192.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_dim: 1d \taugmentation false \twith_focus_attn: True \tmulti_task: false\n",
      "Test accuray: 0.57722\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1080it [00:05, 195.39it/s]\n",
      "360it [00:01, 196.20it/s]\n",
      "1080it [00:05, 192.40it/s]\n",
      "360it [00:01, 196.32it/s]\n",
      "1080it [00:07, 149.02it/s]\n",
      "360it [00:02, 136.62it/s]\n",
      "1080it [00:08, 134.97it/s]\n",
      "360it [00:02, 136.88it/s]\n",
      "1080it [00:07, 143.21it/s]\n",
      "360it [00:02, 136.77it/s]\n",
      "1080it [00:06, 169.02it/s]\n",
      "360it [00:02, 136.66it/s]\n",
      "1080it [00:05, 185.00it/s]\n",
      "360it [00:01, 192.64it/s]\n",
      "1080it [00:05, 193.63it/s]\n",
      "360it [00:01, 195.60it/s]\n",
      "1080it [00:06, 154.57it/s]\n",
      "360it [00:02, 137.14it/s]\n",
      "1080it [00:07, 136.54it/s]\n",
      "360it [00:02, 144.13it/s]\n",
      "20it [00:00, 189.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_dim: 1d \taugmentation false \twith_focus_attn: False \tmulti_task: true\n",
      "Test accuray: 0.56056\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1080it [00:05, 191.88it/s]\n",
      "360it [00:01, 195.77it/s]\n",
      "1080it [00:05, 188.07it/s]\n",
      "360it [00:01, 186.29it/s]\n",
      "1080it [00:05, 193.84it/s]\n",
      "360it [00:01, 194.13it/s]\n",
      "1080it [00:05, 190.89it/s]\n",
      "360it [00:01, 185.61it/s]\n",
      "1080it [00:07, 144.38it/s]\n",
      "360it [00:02, 137.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_dim: 1d \taugmentation false \twith_focus_attn: False \tmulti_task: false\n",
      "Test accuray: 0.56222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# window_size 25ms, hop_size 10ms\n",
    "for conv_dim in conv_dim_list:\n",
    "    for augmentation in augmentation_list:\n",
    "        for with_focus_attn in focus_attn_list:\n",
    "            for multi_task in multi_task_list:\n",
    "                #conv_dim = '1d'\n",
    "                checkpoint = './output/aae_' + conv_dim + '_step_500.pt'\n",
    "                hidden_size = 128\n",
    "                num_layers = 2\n",
    "                bidirectional = 'true'\n",
    "                #with_focus_attn = 'false'\n",
    "\n",
    "                batch_size = 128\n",
    "                num_epochs = 300\n",
    "                learning_rate = 0.0001\n",
    "\n",
    "                use_warmup = 'true'\n",
    "                data_dir = './wav_data/pretrain/RAVDESS_resample/'\n",
    "                #multi_task = 'false'\n",
    "                #augmentation = 'true'\n",
    "\n",
    "                bidirectional = True if(bidirectional == 'true') else False\n",
    "                #with_focus_attn = True if(with_focus_attn == 'true') else False\n",
    "                n_mfcc = 40 if(conv_dim == '1d') else 128\n",
    "\n",
    "                device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "                sample_datas = glob.glob(os.path.join(data_dir, '**', '*wav'), recursive=True)\n",
    "                sample_datas = sorted(sample_datas)\n",
    "\n",
    "                acc_list = []\n",
    "                for i in range(5):\n",
    "                    np.random.seed(10 * i + 3)\n",
    "                    idx = np.random.permutation(len(sample_datas))\n",
    "                    train_idx = idx[:int(len(sample_datas)*0.75)]\n",
    "                    eval_idx = idx[int(len(sample_datas)*0.75):]\n",
    "\n",
    "                    train_samples = list(np.array(sample_datas)[train_idx])\n",
    "                    eval_samples = list(np.array(sample_datas)[eval_idx])\n",
    "\n",
    "                    y = np.array(list(map(lambda x: int(x.split('/')[-1].split('-')[2]) - 1, sample_datas)))\n",
    "                    y_train = y[train_idx]\n",
    "                    y_eval = y[eval_idx]\n",
    "\n",
    "                    if(multi_task == 'true'):\n",
    "                        speaker = np.array(list(map(lambda x: int(x.split('/')[-1].split('-')[-1].split('.')[0]), sample_datas)))\n",
    "                        y_gender = np.array(list(map(lambda x: 1 if x % 2 ==0 else 0, speaker)))\n",
    "\n",
    "                        y_g_train = y_gender[train_idx]\n",
    "                        y_g_eval = y_gender[eval_idx]\n",
    "\n",
    "                    X_train, y_train = convert_spectrograms(train_samples, conv_dim=conv_dim, sr=16000, labels=y_train)\n",
    "                    X_eval, y_eval = convert_spectrograms(eval_samples, conv_dim=conv_dim, sr=16000, labels=y_eval)\n",
    "\n",
    "                    if(augmentation == 'true'):\n",
    "                        X_train_flip = X_train[:, :, :, ::-1]\n",
    "                        y_train_flip = y_train.copy()\n",
    "\n",
    "                        X_train = np.concatenate((X_train, X_train_flip), axis=0)\n",
    "                        y_train = np.concatenate((y_train, y_train_flip), axis=0)\n",
    "                    \n",
    "                    X_train, y_train = convert_tensor(X_train, y_train)\n",
    "                    X_eval, y_eval = convert_tensor(X_eval, y_eval)\n",
    "\n",
    "                    y_train = y_train.long()\n",
    "                    y_eval = y_eval.long()\n",
    "\n",
    "                    if(multi_task == 'true'):\n",
    "                        _, y_g_train = convert_spectrograms(train_samples, conv_dim=conv_dim, sr=16000, labels=y_g_train)\n",
    "                        _, y_g_eval = convert_spectrograms(eval_samples, conv_dim=conv_dim, sr=16000, labels=y_g_eval)\n",
    "\n",
    "                        if(augmentation == 'true'):\n",
    "                            y_g_train_flip = y_g_train.copy()\n",
    "                            y_g_train = np.concatenate((y_g_train, y_g_train_flip))\n",
    "                        \n",
    "                        y_g_train = torch.tensor(y_g_train).float()\n",
    "                        y_g_eval = torch.tensor(y_g_eval).float()\n",
    "\n",
    "                        y_g_train = y_g_train.unsqueeze(-1)\n",
    "                        y_g_eval = y_g_eval.unsqueeze(-1)\n",
    "\n",
    "                    if(multi_task == 'true'):\n",
    "                        train_ds = TensorDataset(X_train, y_train, y_g_train)\n",
    "                        eval_ds = TensorDataset(X_eval, y_eval, y_g_eval)\n",
    "                    else:\n",
    "                        train_ds = TensorDataset(X_train, y_train)\n",
    "                        eval_ds = TensorDataset(X_eval, y_eval)\n",
    "\n",
    "                    train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)\n",
    "                    eval_dataloader = DataLoader(eval_ds, batch_size=batch_size, num_workers=0, drop_last=True)\n",
    "\n",
    "                    model = CLDNN(conv_dim=conv_dim, checkpoint=checkpoint, hidden_size=hidden_size,\n",
    "                                  num_layers=num_layers, bidirectional=bidirectional,\n",
    "                                  with_focus_attn=with_focus_attn).to(device)\n",
    "\n",
    "                    if(multi_task == 'true'):\n",
    "                        model_g = CLDNN_G(conv_dim=conv_dim, checkpoint=checkpoint, hidden_size=hidden_size,\n",
    "                                            num_layers=num_layers, bidirectional=bidirectional,\n",
    "                                            with_focus_attn=with_focus_attn).to(device)\n",
    "\n",
    "                    if(multi_task == 'true'):\n",
    "                        loss_func = nn.CrossEntropyLoss()\n",
    "                        loss_func_g = nn.BCELoss()\n",
    "                        optimizer = optim.Adam(list(model.parameters()) + list(model_g.parameters()), lr=learning_rate)\n",
    "                    else:\n",
    "                        loss_func = nn.CrossEntropyLoss()\n",
    "                        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "                    if(use_warmup == 'true'):\n",
    "                        t_total = len(train_dataloader) // 1 * num_epochs\n",
    "                        opt_scheduler = WarmupLinearSchedule(optimizer, warmup_steps=t_total * 0.1, t_total=t_total)\n",
    "\n",
    "                    train(train_dataloader, eval_dataloader, num_epochs)\n",
    "\n",
    "                    model.eval()\n",
    "                    if(multi_task == 'true'):\n",
    "                        model_g.eval()\n",
    "\n",
    "                    correct = 0\n",
    "                    n = 0\n",
    "                    for i in range(len(eval_samples)):\n",
    "                        try:\n",
    "                            X_new = preprocessing(eval_samples[i], method='mfcc', sr=16000, n_mfcc=n_mfcc)\n",
    "                            X_new = convert_tensor(X_new).to(device)\n",
    "                            y_new = model(X_new)\n",
    "                            y_new = torch.argmax(nn.Softmax(dim=-1)(torch.mean(y_new, dim=0)))\n",
    "                            #y_new = sorted(dict(collections.Counter(torch.argmax(nn.Softmax(dim=-1)(y_new), dim=1).cpu().numpy()))\n",
    "                            #               .items(), key=(lambda x: x[1]), reverse=True)[0][0]\n",
    "                            y_new = 1 if (y_new.item() == y[eval_idx][i].item()) else 0\n",
    "                            correct += y_new\n",
    "                            n += 1\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                    acc = correct / n\n",
    "                    acc_list.append(acc)\n",
    "\n",
    "                acc_mean = sum(acc_list) / 5\n",
    "                print('conv_dim:', conv_dim, '\\taugmentation', augmentation, \n",
    "                      '\\twith_focus_attn:', with_focus_attn, '\\tmulti_task:', multi_task)\n",
    "                print('Test accuray:', round(acc_mean, 5))\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1080it [00:08, 121.94it/s]\n",
      "360it [00:02, 156.14it/s]\n",
      "1080it [00:08, 125.02it/s]\n",
      "360it [00:03, 111.12it/s]\n",
      "1080it [00:09, 118.74it/s]\n",
      "360it [00:02, 156.54it/s]\n",
      "1080it [00:06, 156.71it/s]\n",
      "360it [00:02, 152.83it/s]\n",
      "1080it [00:07, 140.59it/s]\n",
      "360it [00:02, 156.72it/s]\n",
      "1080it [00:06, 157.17it/s]\n",
      "360it [00:02, 154.44it/s]\n",
      "1080it [00:09, 112.73it/s]\n",
      "360it [00:03, 113.30it/s]\n",
      "1080it [00:09, 112.31it/s]\n",
      "360it [00:03, 112.25it/s]\n",
      "1080it [00:07, 141.24it/s]\n",
      "360it [00:02, 157.43it/s]\n",
      "1080it [00:06, 156.25it/s]\n",
      "360it [00:02, 156.27it/s]\n",
      "16it [00:00, 152.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_dim: 1d \taugmentation true \twith_focus_attn: True \tmulti_task: true\n",
      "Test accuray: 0.66611\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1080it [00:08, 125.27it/s]\n",
      "360it [00:03, 100.73it/s]\n",
      "1080it [00:08, 129.36it/s]\n",
      "360it [00:03, 110.84it/s]\n",
      "1080it [00:08, 122.18it/s]\n",
      "360it [00:02, 147.25it/s]\n",
      "1080it [00:09, 113.51it/s]\n",
      "360it [00:03, 112.76it/s]\n",
      "1080it [00:06, 156.06it/s]\n",
      "360it [00:02, 158.27it/s]\n",
      "15it [00:00, 148.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_dim: 1d \taugmentation true \twith_focus_attn: True \tmulti_task: false\n",
      "Test accuray: 0.65167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1080it [00:07, 153.84it/s]\n",
      "360it [00:02, 157.00it/s]\n",
      "1080it [00:07, 153.46it/s]\n",
      "360it [00:02, 149.52it/s]\n",
      "1080it [00:09, 115.36it/s]\n",
      "360it [00:02, 134.57it/s]\n",
      "1080it [00:07, 142.55it/s]\n",
      "360it [00:02, 152.47it/s]\n",
      "1080it [00:06, 156.84it/s]\n",
      "360it [00:02, 155.79it/s]\n",
      "1080it [00:06, 154.90it/s]\n",
      "360it [00:02, 156.61it/s]\n",
      "1080it [00:08, 134.12it/s]\n",
      "360it [00:02, 140.49it/s]\n",
      "1080it [00:07, 153.78it/s]\n",
      "360it [00:02, 120.59it/s]\n",
      "1080it [00:09, 118.57it/s]\n",
      "360it [00:03, 112.30it/s]\n",
      "1080it [00:09, 111.86it/s]\n",
      "360it [00:03, 112.50it/s]\n",
      "12it [00:00, 111.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_dim: 1d \taugmentation true \twith_focus_attn: False \tmulti_task: true\n",
      "Test accuray: 0.63722\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1080it [00:09, 111.29it/s]\n",
      "360it [00:02, 158.29it/s]\n",
      "1080it [00:08, 124.71it/s]\n",
      "360it [00:02, 156.93it/s]\n",
      "1080it [00:06, 155.90it/s]\n",
      "360it [00:02, 154.90it/s]\n",
      "1080it [00:09, 112.15it/s]\n",
      "360it [00:03, 112.40it/s]\n",
      "1080it [00:08, 130.50it/s]\n",
      "360it [00:02, 125.18it/s]\n",
      "15it [00:00, 147.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_dim: 1d \taugmentation true \twith_focus_attn: False \tmulti_task: false\n",
      "Test accuray: 0.67889\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1080it [00:09, 112.75it/s]\n",
      "360it [00:03, 106.24it/s]\n",
      "1080it [00:07, 138.67it/s]\n",
      "360it [00:02, 158.10it/s]\n",
      "1080it [00:08, 123.67it/s]\n",
      "360it [00:02, 157.94it/s]\n",
      "1080it [00:09, 116.57it/s]\n",
      "360it [00:03, 112.75it/s]\n",
      "1080it [00:08, 132.42it/s]\n",
      "360it [00:03, 111.67it/s]\n",
      "1080it [00:09, 118.12it/s]\n",
      "360it [00:02, 158.01it/s]\n",
      "1080it [00:07, 148.03it/s]\n",
      "360it [00:02, 144.80it/s]\n",
      "1080it [00:06, 155.73it/s]\n",
      "360it [00:02, 157.92it/s]\n",
      "1080it [00:07, 145.93it/s]\n",
      "360it [00:02, 151.40it/s]\n",
      "1080it [00:06, 155.70it/s]\n",
      "360it [00:02, 135.73it/s]\n",
      "16it [00:00, 152.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_dim: 1d \taugmentation false \twith_focus_attn: True \tmulti_task: true\n",
      "Test accuray: 0.58056\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1080it [00:10, 100.20it/s]\n",
      "360it [00:03, 99.02it/s] \n",
      "1080it [00:07, 152.37it/s]\n",
      "360it [00:02, 151.50it/s]\n",
      "1080it [00:08, 132.41it/s]\n",
      "360it [00:02, 140.44it/s]\n",
      "1080it [00:06, 156.10it/s]\n",
      "360it [00:02, 152.53it/s]\n",
      "1080it [00:07, 136.20it/s]\n",
      "360it [00:02, 121.28it/s]\n",
      "16it [00:00, 154.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_dim: 1d \taugmentation false \twith_focus_attn: True \tmulti_task: false\n",
      "Test accuray: 0.555\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1080it [00:10, 107.17it/s]\n",
      "360it [00:03, 98.99it/s]\n",
      "1080it [00:09, 117.82it/s]\n",
      "360it [00:02, 153.38it/s]\n",
      "1080it [00:06, 157.77it/s]\n",
      "360it [00:02, 157.11it/s]\n",
      "1080it [00:10, 102.07it/s]\n",
      "360it [00:03, 99.10it/s] \n",
      "1080it [00:06, 156.38it/s]\n",
      "360it [00:02, 156.58it/s]\n",
      "1080it [00:06, 155.63it/s]\n",
      "360it [00:02, 149.67it/s]\n",
      "1080it [00:06, 155.18it/s]\n",
      "360it [00:02, 155.31it/s]\n",
      "1080it [00:06, 155.18it/s]\n",
      "360it [00:02, 150.41it/s]\n",
      "1080it [00:08, 132.19it/s]\n",
      "360it [00:03, 112.17it/s]\n",
      "1080it [00:09, 111.78it/s]\n",
      "360it [00:03, 112.21it/s]\n",
      "16it [00:00, 155.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_dim: 1d \taugmentation false \twith_focus_attn: False \tmulti_task: true\n",
      "Test accuray: 0.57389\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1080it [00:08, 132.40it/s]\n",
      "360it [00:02, 157.34it/s]\n",
      "1080it [00:07, 153.75it/s]\n",
      "360it [00:02, 153.63it/s]\n",
      "1080it [00:08, 131.31it/s]\n",
      "360it [00:03, 110.72it/s]\n",
      "1080it [00:07, 150.66it/s]\n",
      "360it [00:02, 139.47it/s]\n",
      "1080it [00:06, 154.29it/s]\n",
      "360it [00:02, 158.65it/s]\n",
      "11it [00:00, 109.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_dim: 1d \taugmentation false \twith_focus_attn: False \tmulti_task: false\n",
      "Test accuray: 0.56833\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1080it [00:08, 129.52it/s]\n",
      "360it [00:02, 151.79it/s]\n",
      "1080it [00:06, 154.57it/s]\n",
      "360it [00:02, 153.58it/s]\n",
      "1080it [00:07, 142.93it/s]\n",
      "360it [00:02, 121.67it/s]\n",
      "1080it [00:07, 141.18it/s]\n",
      "360it [00:02, 153.88it/s]\n",
      "1080it [00:09, 110.56it/s]\n",
      "360it [00:03, 110.50it/s]\n",
      "1080it [00:07, 146.73it/s]\n",
      "360it [00:03, 117.78it/s]\n",
      "1080it [00:08, 120.55it/s]\n",
      "360it [00:02, 152.17it/s]\n",
      "1080it [00:07, 140.66it/s]\n",
      "360it [00:02, 142.08it/s]\n",
      "1080it [00:08, 120.92it/s]\n",
      "360it [00:02, 155.59it/s]\n",
      "1080it [00:07, 153.97it/s]\n",
      "360it [00:02, 155.30it/s]\n",
      "16it [00:00, 154.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_dim: 2d \taugmentation true \twith_focus_attn: True \tmulti_task: true\n",
      "Test accuray: 0.63944\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1080it [00:08, 123.73it/s]\n",
      "360it [00:02, 140.28it/s]\n",
      "1080it [00:08, 121.29it/s]\n",
      "360it [00:03, 110.63it/s]\n",
      "1080it [00:08, 124.50it/s]\n",
      "360it [00:02, 154.17it/s]\n",
      "1080it [00:07, 143.76it/s]\n",
      "360it [00:02, 155.68it/s]\n",
      "1080it [00:07, 151.43it/s]\n",
      "360it [00:02, 145.39it/s]\n",
      "11it [00:00, 109.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_dim: 2d \taugmentation true \twith_focus_attn: True \tmulti_task: false\n",
      "Test accuray: 0.61778\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1080it [00:07, 143.10it/s]\n",
      "360it [00:02, 130.42it/s]\n",
      "1080it [00:08, 124.34it/s]\n",
      "360it [00:02, 155.48it/s]\n",
      "1080it [00:08, 121.30it/s]\n",
      "360it [00:03, 98.74it/s]\n",
      "1080it [00:07, 142.10it/s]\n",
      "360it [00:02, 130.59it/s]\n",
      "1080it [00:07, 147.42it/s]\n",
      "360it [00:02, 135.23it/s]\n",
      "1080it [00:07, 136.17it/s]\n",
      "360it [00:02, 154.60it/s]\n",
      "1080it [00:09, 111.49it/s]\n",
      "360it [00:03, 109.01it/s]\n",
      "1080it [00:09, 108.81it/s]\n",
      "360it [00:03, 111.52it/s]\n",
      "1080it [00:07, 141.06it/s]\n",
      "360it [00:03, 111.98it/s]\n",
      "1080it [00:07, 151.65it/s]\n",
      "360it [00:03, 111.79it/s]\n",
      "14it [00:00, 137.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_dim: 2d \taugmentation true \twith_focus_attn: False \tmulti_task: true\n",
      "Test accuray: 0.63056\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1080it [00:07, 148.98it/s]\n",
      "360it [00:02, 151.43it/s]\n",
      "1080it [00:07, 151.54it/s]\n",
      "360it [00:02, 155.02it/s]\n",
      "1080it [00:07, 138.66it/s]\n",
      "360it [00:02, 136.73it/s]\n",
      "1080it [00:09, 111.15it/s]\n",
      "360it [00:03, 108.49it/s]\n",
      "1080it [00:09, 113.02it/s]\n",
      "360it [00:03, 110.60it/s]\n",
      "12it [00:00, 110.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_dim: 2d \taugmentation true \twith_focus_attn: False \tmulti_task: false\n",
      "Test accuray: 0.63944\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1080it [00:09, 109.56it/s]\n",
      "360it [00:03, 98.30it/s]\n",
      "1080it [00:10, 103.30it/s]\n",
      "360it [00:03, 111.06it/s]\n",
      "1080it [00:07, 140.18it/s]\n",
      "360it [00:03, 98.69it/s] \n",
      "1080it [00:10, 98.29it/s]\n",
      "360it [00:03, 103.38it/s]\n",
      "1080it [00:09, 119.51it/s]\n",
      "360it [00:02, 147.77it/s]\n",
      "1080it [00:09, 112.68it/s]\n",
      "360it [00:03, 110.90it/s]\n",
      "1080it [00:06, 154.88it/s]\n",
      "360it [00:02, 155.13it/s]\n",
      "1080it [00:07, 144.10it/s]\n",
      "360it [00:02, 155.91it/s]\n",
      "1080it [00:09, 110.89it/s]\n",
      "360it [00:02, 131.46it/s]\n",
      "1080it [00:08, 124.91it/s]\n",
      "360it [00:03, 114.70it/s]\n",
      "11it [00:00, 109.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_dim: 2d \taugmentation false \twith_focus_attn: True \tmulti_task: true\n",
      "Test accuray: 0.61222\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1080it [00:09, 110.76it/s]\n",
      "360it [00:03, 111.39it/s]\n",
      "1080it [00:09, 111.56it/s]\n",
      "360it [00:03, 112.44it/s]\n",
      "1080it [00:08, 120.74it/s]\n",
      "360it [00:03, 111.89it/s]\n",
      "1080it [00:08, 123.92it/s]\n",
      "360it [00:03, 111.05it/s]\n",
      "1080it [00:09, 108.39it/s]\n",
      "360it [00:03, 118.91it/s]\n",
      "12it [00:00, 111.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_dim: 2d \taugmentation false \twith_focus_attn: True \tmulti_task: false\n",
      "Test accuray: 0.62444\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1080it [00:09, 111.65it/s]\n",
      "360it [00:02, 129.49it/s]\n",
      "1080it [00:09, 117.31it/s]\n",
      "360it [00:03, 105.92it/s]\n",
      "1080it [00:07, 141.94it/s]\n",
      "360it [00:03, 111.80it/s]\n",
      "1080it [00:08, 125.33it/s]\n",
      "360it [00:03, 111.48it/s]\n",
      "1080it [00:09, 112.83it/s]\n",
      "360it [00:02, 131.55it/s]\n",
      "1080it [00:07, 141.00it/s]\n",
      "360it [00:02, 155.75it/s]\n",
      "1080it [00:07, 152.82it/s]\n",
      "360it [00:02, 129.43it/s]\n",
      "1080it [00:07, 148.54it/s]\n",
      "360it [00:02, 154.90it/s]\n",
      "1080it [00:09, 114.44it/s]\n",
      "360it [00:03, 111.55it/s]\n",
      "1080it [00:09, 109.60it/s]\n",
      "360it [00:03, 111.91it/s]\n",
      "11it [00:00, 108.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_dim: 2d \taugmentation false \twith_focus_attn: False \tmulti_task: true\n",
      "Test accuray: 0.62167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1080it [00:08, 123.88it/s]\n",
      "360it [00:02, 152.88it/s]\n",
      "1080it [00:06, 155.50it/s]\n",
      "360it [00:02, 157.96it/s]\n",
      "1080it [00:06, 155.31it/s]\n",
      "360it [00:02, 137.84it/s]\n",
      "1080it [00:07, 143.49it/s]\n",
      "360it [00:02, 132.59it/s]\n",
      "1080it [00:07, 138.26it/s]\n",
      "360it [00:02, 155.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_dim: 2d \taugmentation false \twith_focus_attn: False \tmulti_task: false\n",
      "Test accuray: 0.59389\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for conv_dim in conv_dim_list:\n",
    "    for augmentation in augmentation_list:\n",
    "        for with_focus_attn in focus_attn_list:\n",
    "            for multi_task in multi_task_list:\n",
    "                #conv_dim = '1d'\n",
    "                checkpoint = './output/aae_' + conv_dim + '_step_300.pt'\n",
    "                hidden_size = 128\n",
    "                num_layers = 2\n",
    "                bidirectional = 'true'\n",
    "                #with_focus_attn = 'false'\n",
    "\n",
    "                batch_size = 128\n",
    "                num_epochs = 300\n",
    "                learning_rate = 0.0001\n",
    "\n",
    "                use_warmup = 'true'\n",
    "                data_dir = './wav_data/pretrain/RAVDESS_resample/'\n",
    "                #multi_task = 'false'\n",
    "                #augmentation = 'true'\n",
    "\n",
    "                bidirectional = True if(bidirectional == 'true') else False\n",
    "                #with_focus_attn = True if(with_focus_attn == 'true') else False\n",
    "                n_mfcc = 40 if(conv_dim == '1d') else 128\n",
    "\n",
    "                device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "                sample_datas = glob.glob(os.path.join(data_dir, '**', '*wav'), recursive=True)\n",
    "                sample_datas = sorted(sample_datas)\n",
    "\n",
    "                acc_list = []\n",
    "                for i in range(5):\n",
    "                    np.random.seed(10 * i + 3)\n",
    "                    idx = np.random.permutation(len(sample_datas))\n",
    "                    train_idx = idx[:int(len(sample_datas)*0.75)]\n",
    "                    eval_idx = idx[int(len(sample_datas)*0.75):]\n",
    "\n",
    "                    train_samples = list(np.array(sample_datas)[train_idx])\n",
    "                    eval_samples = list(np.array(sample_datas)[eval_idx])\n",
    "\n",
    "                    y = np.array(list(map(lambda x: int(x.split('/')[-1].split('-')[2]) - 1, sample_datas)))\n",
    "                    y_train = y[train_idx]\n",
    "                    y_eval = y[eval_idx]\n",
    "\n",
    "                    if(multi_task == 'true'):\n",
    "                        speaker = np.array(list(map(lambda x: int(x.split('/')[-1].split('-')[-1].split('.')[0]), sample_datas)))\n",
    "                        y_gender = np.array(list(map(lambda x: 1 if x % 2 ==0 else 0, speaker)))\n",
    "\n",
    "                        y_g_train = y_gender[train_idx]\n",
    "                        y_g_eval = y_gender[eval_idx]\n",
    "\n",
    "                    X_train, y_train = convert_spectrograms(train_samples, conv_dim=conv_dim, sr=16000, labels=y_train)\n",
    "                    X_eval, y_eval = convert_spectrograms(eval_samples, conv_dim=conv_dim, sr=16000, labels=y_eval)\n",
    "\n",
    "                    if(augmentation == 'true'):\n",
    "                        X_train_flip = X_train[:, :, :, ::-1]\n",
    "                        y_train_flip = y_train.copy()\n",
    "\n",
    "                        X_train = np.concatenate((X_train, X_train_flip), axis=0)\n",
    "                        y_train = np.concatenate((y_train, y_train_flip), axis=0)\n",
    "                    \n",
    "                    X_train, y_train = convert_tensor(X_train, y_train)\n",
    "                    X_eval, y_eval = convert_tensor(X_eval, y_eval)\n",
    "\n",
    "                    y_train = y_train.long()\n",
    "                    y_eval = y_eval.long()\n",
    "\n",
    "                    if(multi_task == 'true'):\n",
    "                        _, y_g_train = convert_spectrograms(train_samples, conv_dim=conv_dim, sr=16000, labels=y_g_train)\n",
    "                        _, y_g_eval = convert_spectrograms(eval_samples, conv_dim=conv_dim, sr=16000, labels=y_g_eval)\n",
    "\n",
    "                        if(augmentation == 'true'):\n",
    "                            y_g_train_flip = y_g_train.copy()\n",
    "                            y_g_train = np.concatenate((y_g_train, y_g_train_flip))\n",
    "                        \n",
    "                        y_g_train = torch.tensor(y_g_train).float()\n",
    "                        y_g_eval = torch.tensor(y_g_eval).float()\n",
    "\n",
    "                        y_g_train = y_g_train.unsqueeze(-1)\n",
    "                        y_g_eval = y_g_eval.unsqueeze(-1)\n",
    "\n",
    "                    if(multi_task == 'true'):\n",
    "                        train_ds = TensorDataset(X_train, y_train, y_g_train)\n",
    "                        eval_ds = TensorDataset(X_eval, y_eval, y_g_eval)\n",
    "                    else:\n",
    "                        train_ds = TensorDataset(X_train, y_train)\n",
    "                        eval_ds = TensorDataset(X_eval, y_eval)\n",
    "\n",
    "                    train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)\n",
    "                    eval_dataloader = DataLoader(eval_ds, batch_size=batch_size, num_workers=0, drop_last=True)\n",
    "\n",
    "                    model = CLDNN(conv_dim=conv_dim, checkpoint=checkpoint, hidden_size=hidden_size,\n",
    "                                  num_layers=num_layers, bidirectional=bidirectional,\n",
    "                                  with_focus_attn=with_focus_attn).to(device)\n",
    "\n",
    "                    if(multi_task == 'true'):\n",
    "                        model_g = CLDNN_G(conv_dim=conv_dim, checkpoint=checkpoint, hidden_size=hidden_size,\n",
    "                                            num_layers=num_layers, bidirectional=bidirectional,\n",
    "                                            with_focus_attn=with_focus_attn).to(device)\n",
    "\n",
    "                    if(multi_task == 'true'):\n",
    "                        loss_func = nn.CrossEntropyLoss()\n",
    "                        loss_func_g = nn.BCELoss()\n",
    "                        optimizer = optim.Adam(list(model.parameters()) + list(model_g.parameters()), lr=learning_rate)\n",
    "                    else:\n",
    "                        loss_func = nn.CrossEntropyLoss()\n",
    "                        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "                    if(use_warmup == 'true'):\n",
    "                        t_total = len(train_dataloader) // 1 * num_epochs\n",
    "                        opt_scheduler = WarmupLinearSchedule(optimizer, warmup_steps=t_total * 0.1, t_total=t_total)\n",
    "\n",
    "                    train(train_dataloader, eval_dataloader, num_epochs)\n",
    "\n",
    "                    model.eval()\n",
    "                    if(multi_task == 'true'):\n",
    "                        model_g.eval()\n",
    "\n",
    "                    correct = 0\n",
    "                    n = 0\n",
    "                    for i in range(len(eval_samples)):\n",
    "                        try:\n",
    "                            X_new = preprocessing(eval_samples[i], method='mfcc', sr=16000, n_mfcc=n_mfcc)\n",
    "                            X_new = convert_tensor(X_new).to(device)\n",
    "                            y_new = model(X_new)\n",
    "                            y_new = torch.argmax(nn.Softmax(dim=-1)(torch.mean(y_new, dim=0)))\n",
    "                            #y_new = sorted(dict(collections.Counter(torch.argmax(nn.Softmax(dim=-1)(y_new), dim=1).cpu().numpy()))\n",
    "                            #               .items(), key=(lambda x: x[1]), reverse=True)[0][0]\n",
    "                            y_new = 1 if (y_new.item() == y[eval_idx][i].item()) else 0\n",
    "                            correct += y_new\n",
    "                            n += 1\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                    acc = correct / n\n",
    "                    acc_list.append(acc)\n",
    "\n",
    "                acc_mean = sum(acc_list) / 5\n",
    "                print('conv_dim:', conv_dim, '\\taugmentation', augmentation, \n",
    "                      '\\twith_focus_attn:', with_focus_attn, '\\tmulti_task:', multi_task)\n",
    "                print('Test accuray:', round(acc_mean, 5))\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl",
   "language": "python",
   "name": "mldl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
