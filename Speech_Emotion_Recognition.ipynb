{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from preprocessing import preprocessing, convert_spectrograms, convert_tensor\n",
    "from model_ae import Encoder\n",
    "from utils.optimization import WarmupLinearSchedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_dim = '1d'\n",
    "checkpoint = './output/aae_1d_step_300.pt'\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "bidirectional = 'true'\n",
    "with_focus_attn = 'true'\n",
    "\n",
    "batch_size = 128\n",
    "num_epochs = 300\n",
    "learning_rate = 0.0001\n",
    "\n",
    "use_warmup = 'true'\n",
    "data_dir = './wav_data/pretrain/RAVDESS_resample/'\n",
    "multi_task = 'true'\n",
    "augmentation = 'true'\n",
    "\n",
    "bidirectional = True if(bidirectional == 'true') else False\n",
    "with_focus_attn = True if(with_focus_attn == 'true') else False\n",
    "n_mfcc = 40 if(conv_dim == '1d') else 128\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "sample_datas = glob.glob(os.path.join(data_dir, '**', '*wav'), recursive=True)\n",
    "sample_datas = sorted(sample_datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, num_attn_heads, attn_hidden_size, dropout_prob, with_focus_attn):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        self.num_attn_heads = num_attn_heads\n",
    "        self.hidden_size = attn_hidden_size\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.with_focus_attn = with_focus_attn\n",
    "        \n",
    "        self.attn_head_size = int(self.hidden_size / self.num_attn_heads)\n",
    "        self.all_head_size = self.num_attn_heads * self.attn_head_size\n",
    "\n",
    "        self.query = nn.Linear(self.hidden_size, self.all_head_size)\n",
    "        self.key = nn.Linear(self.hidden_size, self.all_head_size)\n",
    "        self.value = nn.Linear(self.hidden_size, self.all_head_size)\n",
    "\n",
    "        self.o_proj = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_prob)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "        if(with_focus_attn == True):\n",
    "            self.tanh = nn.Tanh()\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "            \n",
    "            self.linear_focus_query = nn.Linear(num_attn_heads * self.attn_head_size, \n",
    "                                                num_attn_heads * self.attn_head_size)\n",
    "            self.linear_focus_global = nn.Linear(num_attn_heads * self.attn_head_size, \n",
    "                                                 num_attn_heads * self.attn_head_size)\n",
    "            \n",
    "            up = torch.randn(num_attn_heads, 1, self.attn_head_size)\n",
    "            self.up = Variable(up, requires_grad=True).cuda()\n",
    "            torch.nn.init.xavier_uniform_(self.up)\n",
    "            \n",
    "            uz = torch.randn(num_attn_heads, 1, self.attn_head_size)\n",
    "            self.uz = Variable(uz, requires_grad=True).cuda()\n",
    "            torch.nn.init.xavier_uniform_(self.uz)\n",
    "\n",
    "    def transpose_for_scores(self, x):\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attn_heads, self.attn_head_size)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        key_len = hidden_states.size(1)\n",
    "        \n",
    "        mixed_query_layer = self.query(hidden_states)\n",
    "        mixed_key_layer = self.key(hidden_states)\n",
    "        mixed_value_layer = self.value(hidden_states)\n",
    "        \n",
    "        if(self.with_focus_attn == True):\n",
    "            glo = torch.mean(mixed_query_layer, dim=1, keepdim=True)\n",
    "            \n",
    "            c = self.tanh(self.linear_focus_query(mixed_query_layer) + self.linear_focus_global(glo))\n",
    "            c = self.transpose_for_scores(c)\n",
    "            \n",
    "            p = c * self.up\n",
    "            p = p.sum(3).squeeze()\n",
    "            z = c * self.uz\n",
    "            z = z.sum(3).squeeze()\n",
    "            \n",
    "            P = self.sigmoid(p) * key_len\n",
    "            Z = self.sigmoid(z) * key_len\n",
    "            \n",
    "            j = torch.arange(start=0, end=key_len, dtype=P.dtype).unsqueeze(0).unsqueeze(0).unsqueeze(0).to('cuda')\n",
    "            P = P.unsqueeze(-1)\n",
    "            Z = Z.unsqueeze(-1)\n",
    "            \n",
    "            G = -(j - P)**2 * 2 / (Z**2)\n",
    "\n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
    "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
    "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
    "\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "        attention_scores = attention_scores / math.sqrt(self.attn_head_size)\n",
    "        \n",
    "        if(self.with_focus_attn == True):\n",
    "            attention_scores = attention_scores + G\n",
    "            \n",
    "        attention_probs = self.softmax(attention_scores)\n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)\n",
    "        attention_output = self.o_proj(context_layer)\n",
    "\n",
    "        return attention_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLDNN(nn.Module):\n",
    "    def __init__(self, conv_dim, checkpoint=None, hidden_size=64, num_layers=2,\n",
    "                 bidirectional=True, with_focus_attn=False):\n",
    "        super(CLDNN, self).__init__()\n",
    "        self.conv_dim = conv_dim\n",
    "        if(conv_dim == '1d'):\n",
    "            self.encoder = Encoder(conv_dim)\n",
    "            if checkpoint:\n",
    "                self.encoder.load_state_dict(torch.load(checkpoint))\n",
    "            self.attn = MultiHeadedAttention(num_attn_heads=4, attn_hidden_size=8, dropout_prob=0.1,\n",
    "                                             with_focus_attn=with_focus_attn)\n",
    "            self.lstm = nn.LSTM(8, hidden_size=hidden_size, num_layers=num_layers, bidirectional=bidirectional)\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(hidden_size*2 if bidirectional else hidden_size, 8),\n",
    "            )\n",
    "        elif(conv_dim == '2d'):\n",
    "            self.encoder = Encoder(conv_dim)\n",
    "            if checkpoint:\n",
    "                self.encoder.load_state_dict(torch.load(checkpoint))\n",
    "            self.attn = MultiHeadedAttention(num_attn_heads=4, attn_hidden_size=176, dropout_prob=0.1, \n",
    "                                             with_focus_attn=with_focus_attn)\n",
    "            self.gap = nn.AdaptiveAvgPool2d((1, 11))\n",
    "            self.lstm = nn.LSTM(11, hidden_size=hidden_size, num_layers=num_layers, bidirectional=bidirectional)\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(hidden_size*2 if bidirectional else hidden_size, 8),\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Convolution dimension not found: %s\" % (conv_dim))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        if(self.conv_dim == '1d'):\n",
    "            out = self.encoder(x)  # (batch, 1, 40, 100) -> (batch, 8, 1, 100)\n",
    "            out = torch.squeeze(out, 2)  # (batch, 8, 1, 100) -> (batch, 8, 100)\n",
    "            out = out.permute(0, 2, 1)  # (batch, 8, 100) -> (batch, 100, 8)\n",
    "            h = out\n",
    "            out = self.attn(out)  # (batch, 100, 8) -> (batch, 100, 8)\n",
    "            out = h + out\n",
    "            out = out.permute(1, 0, 2)  # (batch, 100, 8) -> (100, batch, 8)\n",
    "            self.lstm.flatten_parameters()\n",
    "            out, _ = self.lstm(out)  # (100, batch, 8) -> (100, batch, num_directions*hidden_size)\n",
    "            out = out[-1]  # (100, batch, num_directions*hidden_size) -> (batch, num_directions*hidden_size)\n",
    "            out = self.fc(out)  # (batch, num_directions*hidden_size) -> (batch, 1)\n",
    "        elif(self.conv_dim == '2d'):\n",
    "            out = self.encoder(x)  # (batch, 1, 128, 100) -> (batch, 16, 11, 8)\n",
    "            out = out.permute(0, 3, 1, 2)  # (batch, 16, 11, 8) -> (batch, 8, 16, 11)\n",
    "            h = out\n",
    "            new_out_shape = out.size()[:2] + (out.size()[2] * out.size()[3],)\n",
    "            out = out.view(*new_out_shape)  # (batch, 8, 16, 11) -> (batch, 8, 176)\n",
    "            out = self.attn(out)  # (batch, 8, 176) -> (batch, 8, 176)\n",
    "            out = out.view(h.size())  # (batch, 8, 176) -> (batch, 8, 16, 11)\n",
    "            out = h + out\n",
    "            out = self.gap(out)  # (batch, 8, 16, 11) -> (batch, 8, 1, 11)\n",
    "            out = torch.squeeze(out, 2)  # (batch, 8, 1, 11) -> (batch, 8, 11)\n",
    "            out = out.permute(1, 0, 2)  # (batch, 8, 11) -> (8, batch, 11)\n",
    "            self.lstm.flatten_parameters()\n",
    "            out, _ = self.lstm(out)  # (8, batch, 11) -> (8, batch, num_directions*hidden_size)\n",
    "            out = out[-1]  # (8, batch, num_directions*hidden_size) -> (batch, num_directions*hidden_size)\n",
    "            out = self.fc(out)  # (batch, num_directions*hidden_size) -> (batch, 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLDNN_G(nn.Module):\n",
    "    def __init__(self, conv_dim, checkpoint=None, hidden_size=64, num_layers=2,\n",
    "                 bidirectional=True, with_focus_attn=False):\n",
    "        super(CLDNN_G, self).__init__()\n",
    "        self.conv_dim = conv_dim\n",
    "        if(conv_dim == '1d'):\n",
    "            self.encoder = Encoder(conv_dim)\n",
    "            if checkpoint:\n",
    "                self.encoder.load_state_dict(torch.load(checkpoint))\n",
    "            self.attn = MultiHeadedAttention(num_attn_heads=4, attn_hidden_size=8, dropout_prob=0.1,\n",
    "                                             with_focus_attn=with_focus_attn)\n",
    "            self.lstm = nn.LSTM(8, hidden_size=hidden_size, num_layers=num_layers, bidirectional=bidirectional)\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(hidden_size*2 if bidirectional else hidden_size, 1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        elif(conv_dim == '2d'):\n",
    "            self.encoder = Encoder(conv_dim)\n",
    "            if checkpoint:\n",
    "                self.encoder.load_state_dict(torch.load(checkpoint))\n",
    "            self.attn = MultiHeadedAttention(num_attn_heads=4, attn_hidden_size=176, dropout_prob=0.1, \n",
    "                                             with_focus_attn=with_focus_attn)\n",
    "            self.gap = nn.AdaptiveAvgPool2d((1, 11))\n",
    "            self.lstm = nn.LSTM(11, hidden_size=hidden_size, num_layers=num_layers, bidirectional=bidirectional)\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(hidden_size*2 if bidirectional else hidden_size, 1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Convolution dimension not found: %s\" % (conv_dim))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        if(self.conv_dim == '1d'):\n",
    "            out = self.encoder(x)  # (batch, 1, 40, 100) -> (batch, 8, 1, 100)\n",
    "            out = torch.squeeze(out, 2)  # (batch, 8, 1, 100) -> (batch, 8, 100)\n",
    "            out = out.permute(0, 2, 1)  # (batch, 8, 100) -> (batch, 100, 8)\n",
    "            h = out\n",
    "            out = self.attn(out)  # (batch, 100, 8) -> (batch, 100, 8)\n",
    "            out = h + out\n",
    "            out = out.permute(1, 0, 2)  # (batch, 100, 8) -> (100, batch, 8)\n",
    "            self.lstm.flatten_parameters()\n",
    "            out, _ = self.lstm(out)  # (100, batch, 8) -> (100, batch, num_directions*hidden_size)\n",
    "            out = out[-1]  # (100, batch, num_directions*hidden_size) -> (batch, num_directions*hidden_size)\n",
    "            out = self.fc(out)  # (batch, num_directions*hidden_size) -> (batch, 1)\n",
    "        elif(self.conv_dim == '2d'):\n",
    "            out = self.encoder(x)  # (batch, 1, 128, 100) -> (batch, 16, 11, 8)\n",
    "            out = out.permute(0, 3, 1, 2)  # (batch, 16, 11, 8) -> (batch, 8, 16, 11)\n",
    "            h = out\n",
    "            new_out_shape = out.size()[:2] + (out.size()[2] * out.size()[3],)\n",
    "            out = out.view(*new_out_shape)  # (batch, 8, 16, 11) -> (batch, 8, 176)\n",
    "            out = self.attn(out)  # (batch, 8, 176) -> (batch, 8, 176)\n",
    "            out = out.view(h.size())  # (batch, 8, 176) -> (batch, 8, 16, 11)\n",
    "            out = h + out\n",
    "            out = self.gap(out)  # (batch, 8, 16, 11) -> (batch, 8, 1, 11)\n",
    "            out = torch.squeeze(out, 2)  # (batch, 8, 1, 11) -> (batch, 8, 11)\n",
    "            out = out.permute(1, 0, 2)  # (batch, 8, 11) -> (8, batch, 11)\n",
    "            self.lstm.flatten_parameters()\n",
    "            out, _ = self.lstm(out)  # (8, batch, 11) -> (8, batch, num_directions*hidden_size)\n",
    "            out = out[-1]  # (8, batch, num_directions*hidden_size) -> (batch, num_directions*hidden_size)\n",
    "            out = self.fc(out)  # (batch, num_directions*hidden_size) -> (batch, 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "idx = np.random.permutation(int(len(sample_datas)/2))  # add\n",
    "\n",
    "train_idx = idx[:int((len(sample_datas)/2)*0.75)]  # add\n",
    "eval_idx = idx[int((len(sample_datas)/2)*0.75):]  # add\n",
    "noise_idx = np.arange((int(len(sample_datas)/2)), len(sample_datas))  # add\n",
    "train_idx = np.r_[train_idx, noise_idx]  # add\n",
    "\n",
    "train_samples = list(np.array(sample_datas)[train_idx])\n",
    "eval_samples = list(np.array(sample_datas)[eval_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(list(map(lambda x: int(x.split('/')[-1].split('-')[2]) - 1, sample_datas)))\n",
    "y_train = y[train_idx]\n",
    "y_eval = y[eval_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(multi_task == 'true'):\n",
    "    speaker = np.array(list(map(lambda x: int(x.split('/')[-1].split('-')[-1].split('.')[0].split('_')[0]), \n",
    "                                sample_datas)))  # add\n",
    "    y_gender = np.array(list(map(lambda x: 1 if x % 2 ==0 else 0, speaker)))\n",
    "\n",
    "    y_g_train = y_gender[train_idx]\n",
    "    y_g_eval = y_gender[eval_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2520it [00:13, 186.76it/s]\n",
      "360it [00:01, 197.02it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = convert_spectrograms(train_samples, conv_dim=conv_dim, sr=16000, labels=y_train)\n",
    "X_eval, y_eval = convert_spectrograms(eval_samples, conv_dim=conv_dim, sr=16000, labels=y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(augmentation == 'true'):\n",
    "    X_train_flip = X_train[:, :, :, ::-1]\n",
    "    y_train_flip = y_train.copy()\n",
    "\n",
    "    X_train = np.concatenate((X_train, X_train_flip), axis=0)\n",
    "    y_train = np.concatenate((y_train, y_train_flip), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = convert_tensor(X_train, y_train)\n",
    "X_eval, y_eval = convert_tensor(X_eval, y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.long()\n",
    "y_eval = y_eval.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2520it [00:12, 194.76it/s]\n",
      "360it [00:01, 198.27it/s]\n"
     ]
    }
   ],
   "source": [
    "if(multi_task == 'true'):\n",
    "    _, y_g_train = convert_spectrograms(train_samples, conv_dim=conv_dim, sr=16000, labels=y_g_train)\n",
    "    _, y_g_eval = convert_spectrograms(eval_samples, conv_dim=conv_dim, sr=16000, labels=y_g_eval)\n",
    "    \n",
    "    if(augmentation == 'true'):\n",
    "        y_g_train_flip = y_g_train.copy()\n",
    "        y_g_train = np.concatenate((y_g_train, y_g_train_flip))\n",
    "    \n",
    "    y_g_train = torch.tensor(y_g_train).float()\n",
    "    y_g_eval = torch.tensor(y_g_eval).float()\n",
    "\n",
    "    y_g_train = y_g_train.unsqueeze(-1)\n",
    "    y_g_eval = y_g_eval.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([164482, 1, 40, 50]) torch.Size([164482]) torch.Size([164482, 1]) torch.Size([11753, 1, 40, 50]) torch.Size([11753]) torch.Size([11753, 1])\n"
     ]
    }
   ],
   "source": [
    "if(multi_task == 'true'):\n",
    "    print(X_train.shape, y_train.shape, y_g_train.shape, X_eval.shape, y_eval.shape, y_g_eval.shape)\n",
    "else:\n",
    "    print(X_train.shape, y_train.shape, X_eval.shape, y_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(multi_task == 'true'):\n",
    "    train_ds = TensorDataset(X_train, y_train, y_g_train)\n",
    "    eval_ds = TensorDataset(X_eval, y_eval, y_g_eval)\n",
    "else:\n",
    "    train_ds = TensorDataset(X_train, y_train)\n",
    "    eval_ds = TensorDataset(X_eval, y_eval)\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)\n",
    "eval_dataloader = DataLoader(eval_ds, batch_size=batch_size, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLDNN(conv_dim=conv_dim, checkpoint=checkpoint, hidden_size=hidden_size,\n",
    "              num_layers=num_layers, bidirectional=bidirectional,\n",
    "              with_focus_attn=with_focus_attn).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(multi_task == 'true'):\n",
    "    model_g = CLDNN_G(conv_dim=conv_dim, checkpoint=checkpoint, hidden_size=hidden_size,\n",
    "                        num_layers=num_layers, bidirectional=bidirectional,\n",
    "                        with_focus_attn=with_focus_attn).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(multi_task == 'true'):\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    loss_func_g = nn.BCELoss()\n",
    "    optimizer = optim.Adam(list(model.parameters()) + list(model_g.parameters()), lr=learning_rate)\n",
    "else:\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(use_warmup == 'true'):\n",
    "    t_total = len(train_dataloader) // 1 * num_epochs\n",
    "    opt_scheduler = WarmupLinearSchedule(optimizer, warmup_steps=t_total * 0.1, t_total=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, eval_dataloader, epochs):\n",
    "        print('Start training')\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            nb_train_steps = 0\n",
    "            correct = 0\n",
    "            num_samples = 0\n",
    "            \n",
    "            if(multi_task == 'true'):\n",
    "                for X_batch, y_batch, y_g_batch in train_dataloader:\n",
    "                    X_batch = X_batch.to(device)\n",
    "                    y_batch = y_batch.to(device)\n",
    "                    y_g_batch = y_g_batch.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    outputs = model(X_batch)\n",
    "                    outputs_g = model_g(X_batch)\n",
    "\n",
    "                    loss_1 = loss_func(outputs, y_batch)\n",
    "                    loss_2 = loss_func_g(outputs_g, y_g_batch)\n",
    "                    loss = loss_1 + 0.8 * loss_2\n",
    "                    loss.backward(retain_graph=True)\n",
    "\n",
    "                    optimizer.step()\n",
    "                    opt_scheduler.step()\n",
    "\n",
    "                    train_loss += loss.mean().item()\n",
    "                    nb_train_steps += 1\n",
    "\n",
    "                    outputs = softmax(outputs)\n",
    "                    outputs = torch.argmax(outputs, dim=1)\n",
    "                    correct += (outputs == y_batch).float().sum()\n",
    "                    num_samples += len(X_batch)\n",
    "\n",
    "                train_loss = train_loss / nb_train_steps\n",
    "                train_accuracy = correct / num_samples\n",
    "\n",
    "                model.eval()\n",
    "                eval_loss = 0\n",
    "                nb_eval_steps = 0\n",
    "                correct = 0\n",
    "                num_samples = 0\n",
    "\n",
    "                for X_batch, y_batch, y_g_batch in eval_dataloader:\n",
    "                    X_batch = X_batch.to(device)\n",
    "                    y_batch = y_batch.to(device)\n",
    "                    y_g_batch = y_g_batch.to(device)\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(X_batch)\n",
    "                        outputs_g = model_g(X_batch)\n",
    "\n",
    "                    tmp_eval_loss_1 = loss_func(outputs, y_batch)\n",
    "                    tmp_eval_loss_2 = loss_func_g(outputs_g, y_g_batch)\n",
    "                    tmp_eval_loss = tmp_eval_loss_1 + 0.8 * tmp_eval_loss_2\n",
    "                    eval_loss += tmp_eval_loss.mean().item()\n",
    "                    nb_eval_steps += 1\n",
    "\n",
    "                    outputs = softmax(outputs)\n",
    "                    outputs = torch.argmax(outputs, dim=1)\n",
    "                    correct += (outputs == y_batch).float().sum()\n",
    "                    num_samples += len(X_batch)\n",
    "\n",
    "                eval_loss = eval_loss / nb_eval_steps\n",
    "                eval_accuracy = correct / num_samples\n",
    "            else:\n",
    "                for X_batch, y_batch in train_dataloader:\n",
    "                    X_batch = X_batch.to(device)\n",
    "                    y_batch = y_batch.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    outputs = model(X_batch)\n",
    "\n",
    "                    loss = loss_func(outputs, y_batch)\n",
    "                    loss.backward()\n",
    "\n",
    "                    optimizer.step()\n",
    "                    opt_scheduler.step()\n",
    "\n",
    "                    train_loss += loss.mean().item()\n",
    "                    nb_train_steps += 1\n",
    "\n",
    "                    outputs = softmax(outputs)\n",
    "                    outputs = torch.argmax(outputs, dim=1)\n",
    "                    correct += (outputs == y_batch).float().sum()\n",
    "                    num_samples += len(X_batch)\n",
    "\n",
    "                train_loss = train_loss / nb_train_steps\n",
    "                train_accuracy = correct / num_samples\n",
    "\n",
    "                model.eval()\n",
    "                eval_loss = 0\n",
    "                nb_eval_steps = 0\n",
    "                correct = 0\n",
    "                num_samples = 0\n",
    "\n",
    "                for X_batch, y_batch in eval_dataloader:\n",
    "                    X_batch = X_batch.to(device)\n",
    "                    y_batch = y_batch.to(device)\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(X_batch)\n",
    "\n",
    "                    tmp_eval_loss = loss_func(outputs, y_batch)\n",
    "                    eval_loss += tmp_eval_loss.mean().item()\n",
    "                    nb_eval_steps += 1\n",
    "\n",
    "                    outputs = softmax(outputs)\n",
    "                    outputs = torch.argmax(outputs, dim=1)\n",
    "                    correct += (outputs == y_batch).float().sum()\n",
    "                    num_samples += len(X_batch)\n",
    "\n",
    "                eval_loss = eval_loss / nb_eval_steps\n",
    "                eval_accuracy = correct / num_samples\n",
    "\n",
    "            for param_group in optimizer.param_groups:\n",
    "                lr = param_group['lr']\n",
    "            print('epoch: {:3d},    lr={:6f},    loss={:5f},    train_acc={:5f},    eval_loss={:5f},    eval_acc={:5f}'\n",
    "                  .format(epoch+1, lr, train_loss, train_accuracy, eval_loss, eval_accuracy))\n",
    "\n",
    "            '''\n",
    "            if((epoch+1) % args.save_checkpoint_steps == 0):\n",
    "                model_checkpoint = \"%s_%s_step_%d.pt\" % ('CLDNN', args.conv_dim, epoch+1)\n",
    "                output_model_file = os.path.join(args.output_dir, model_checkpoint)\n",
    "                if(args.multi_gpu == 'true'):\n",
    "                    torch.save(model.module.state_dict(), output_model_file)\n",
    "                else:\n",
    "                    torch.save(model.state_dict(), output_model_file)\n",
    "                print(\"Saving checkpoint %s\" % output_model_file)\n",
    "            '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "epoch:   1,    lr=0.000003,    loss=2.639787,    train_acc=0.102243,    eval_loss=2.633282,    eval_acc=0.127833\n",
      "epoch:   2,    lr=0.000007,    loss=2.621876,    train_acc=0.139002,    eval_loss=2.607576,    eval_acc=0.152816\n",
      "epoch:   3,    lr=0.000010,    loss=2.605483,    train_acc=0.154080,    eval_loss=2.594278,    eval_acc=0.174708\n",
      "epoch:   4,    lr=0.000013,    loss=2.485093,    train_acc=0.195738,    eval_loss=2.456204,    eval_acc=0.214629\n",
      "epoch:   5,    lr=0.000017,    loss=2.368280,    train_acc=0.217546,    eval_loss=2.468733,    eval_acc=0.207503\n",
      "epoch:   6,    lr=0.000020,    loss=2.313907,    train_acc=0.220033,    eval_loss=2.502094,    eval_acc=0.211796\n",
      "epoch:   7,    lr=0.000023,    loss=2.264407,    train_acc=0.224769,    eval_loss=2.542623,    eval_acc=0.217806\n",
      "epoch:   8,    lr=0.000027,    loss=2.228291,    train_acc=0.231141,    eval_loss=2.608542,    eval_acc=0.218063\n",
      "epoch:   9,    lr=0.000030,    loss=2.200482,    train_acc=0.236424,    eval_loss=2.638588,    eval_acc=0.223472\n",
      "epoch:  10,    lr=0.000033,    loss=2.177295,    train_acc=0.240649,    eval_loss=2.675680,    eval_acc=0.231113\n",
      "epoch:  11,    lr=0.000037,    loss=2.153607,    train_acc=0.246571,    eval_loss=2.633850,    eval_acc=0.250258\n",
      "epoch:  12,    lr=0.000040,    loss=2.133531,    train_acc=0.253897,    eval_loss=2.611547,    eval_acc=0.245793\n",
      "epoch:  13,    lr=0.000043,    loss=2.113859,    train_acc=0.263515,    eval_loss=2.532303,    eval_acc=0.264766\n",
      "epoch:  14,    lr=0.000047,    loss=2.091252,    train_acc=0.271358,    eval_loss=2.518094,    eval_acc=0.269231\n",
      "epoch:  15,    lr=0.000050,    loss=2.073933,    train_acc=0.278016,    eval_loss=2.436088,    eval_acc=0.269918\n",
      "epoch:  16,    lr=0.000053,    loss=2.056736,    train_acc=0.282314,    eval_loss=2.423575,    eval_acc=0.273180\n",
      "epoch:  17,    lr=0.000057,    loss=2.042112,    train_acc=0.288284,    eval_loss=2.443078,    eval_acc=0.289663\n",
      "epoch:  18,    lr=0.000060,    loss=2.024295,    train_acc=0.295659,    eval_loss=2.364047,    eval_acc=0.290608\n",
      "epoch:  19,    lr=0.000063,    loss=2.013515,    train_acc=0.300559,    eval_loss=2.366620,    eval_acc=0.302112\n",
      "epoch:  20,    lr=0.000067,    loss=2.000314,    train_acc=0.303095,    eval_loss=2.367669,    eval_acc=0.296016\n",
      "epoch:  21,    lr=0.000070,    loss=1.990377,    train_acc=0.306931,    eval_loss=2.343598,    eval_acc=0.307778\n",
      "epoch:  22,    lr=0.000073,    loss=1.978910,    train_acc=0.308311,    eval_loss=2.274267,    eval_acc=0.317909\n",
      "epoch:  23,    lr=0.000077,    loss=1.971904,    train_acc=0.312731,    eval_loss=2.266459,    eval_acc=0.331559\n",
      "epoch:  24,    lr=0.000080,    loss=1.959670,    train_acc=0.318008,    eval_loss=2.269764,    eval_acc=0.327867\n",
      "epoch:  25,    lr=0.000083,    loss=1.955438,    train_acc=0.318428,    eval_loss=2.225664,    eval_acc=0.338427\n",
      "epoch:  26,    lr=0.000087,    loss=1.942898,    train_acc=0.322696,    eval_loss=2.249789,    eval_acc=0.339629\n",
      "epoch:  27,    lr=0.000090,    loss=1.934603,    train_acc=0.325578,    eval_loss=2.173894,    eval_acc=0.336023\n",
      "epoch:  28,    lr=0.000093,    loss=1.923743,    train_acc=0.331262,    eval_loss=2.169435,    eval_acc=0.350446\n",
      "epoch:  29,    lr=0.000097,    loss=1.915192,    train_acc=0.334022,    eval_loss=2.268260,    eval_acc=0.310955\n",
      "epoch:  30,    lr=0.000100,    loss=1.904272,    train_acc=0.337081,    eval_loss=2.192649,    eval_acc=0.357143\n",
      "epoch:  31,    lr=0.000100,    loss=1.896306,    train_acc=0.341859,    eval_loss=2.180253,    eval_acc=0.354224\n",
      "epoch:  32,    lr=0.000099,    loss=1.885237,    train_acc=0.344759,    eval_loss=2.119648,    eval_acc=0.348644\n",
      "epoch:  33,    lr=0.000099,    loss=1.874616,    train_acc=0.349921,    eval_loss=2.122263,    eval_acc=0.349760\n",
      "epoch:  34,    lr=0.000099,    loss=1.865760,    train_acc=0.352213,    eval_loss=2.179295,    eval_acc=0.326666\n",
      "epoch:  35,    lr=0.000098,    loss=1.857200,    train_acc=0.355891,    eval_loss=2.175216,    eval_acc=0.348815\n",
      "epoch:  36,    lr=0.000098,    loss=1.848230,    train_acc=0.359387,    eval_loss=2.042662,    eval_acc=0.371394\n",
      "epoch:  37,    lr=0.000097,    loss=1.840130,    train_acc=0.362476,    eval_loss=2.042770,    eval_acc=0.367960\n",
      "epoch:  38,    lr=0.000097,    loss=1.832941,    train_acc=0.363564,    eval_loss=2.072415,    eval_acc=0.361264\n",
      "epoch:  39,    lr=0.000097,    loss=1.823935,    train_acc=0.368841,    eval_loss=2.089734,    eval_acc=0.374828\n",
      "epoch:  40,    lr=0.000096,    loss=1.814863,    train_acc=0.370799,    eval_loss=2.053474,    eval_acc=0.375944\n",
      "epoch:  41,    lr=0.000096,    loss=1.805875,    train_acc=0.375261,    eval_loss=2.029189,    eval_acc=0.380065\n",
      "epoch:  42,    lr=0.000096,    loss=1.797566,    train_acc=0.378776,    eval_loss=2.064233,    eval_acc=0.365556\n",
      "epoch:  43,    lr=0.000095,    loss=1.791159,    train_acc=0.382581,    eval_loss=2.038374,    eval_acc=0.374056\n",
      "epoch:  44,    lr=0.000095,    loss=1.780975,    train_acc=0.385111,    eval_loss=2.022353,    eval_acc=0.370622\n",
      "epoch:  45,    lr=0.000094,    loss=1.773351,    train_acc=0.388175,    eval_loss=1.998165,    eval_acc=0.372339\n",
      "epoch:  46,    lr=0.000094,    loss=1.766597,    train_acc=0.391044,    eval_loss=1.969916,    eval_acc=0.370622\n",
      "epoch:  47,    lr=0.000094,    loss=1.757006,    train_acc=0.394285,    eval_loss=2.036880,    eval_acc=0.376374\n",
      "epoch:  48,    lr=0.000093,    loss=1.750437,    train_acc=0.398206,    eval_loss=2.042418,    eval_acc=0.379722\n",
      "epoch:  49,    lr=0.000093,    loss=1.741043,    train_acc=0.400730,    eval_loss=1.990435,    eval_acc=0.375343\n",
      "epoch:  50,    lr=0.000093,    loss=1.733156,    train_acc=0.404700,    eval_loss=2.033663,    eval_acc=0.392600\n",
      "epoch:  51,    lr=0.000092,    loss=1.728000,    train_acc=0.407423,    eval_loss=2.003074,    eval_acc=0.382383\n",
      "epoch:  52,    lr=0.000092,    loss=1.719518,    train_acc=0.410111,    eval_loss=1.992273,    eval_acc=0.380151\n",
      "epoch:  53,    lr=0.000091,    loss=1.709862,    train_acc=0.414360,    eval_loss=1.940982,    eval_acc=0.382212\n",
      "epoch:  54,    lr=0.000091,    loss=1.701869,    train_acc=0.414652,    eval_loss=2.009314,    eval_acc=0.380409\n",
      "epoch:  55,    lr=0.000091,    loss=1.694181,    train_acc=0.420009,    eval_loss=1.960256,    eval_acc=0.380752\n",
      "epoch:  56,    lr=0.000090,    loss=1.685760,    train_acc=0.423559,    eval_loss=1.943052,    eval_acc=0.388307\n",
      "epoch:  57,    lr=0.000090,    loss=1.676982,    train_acc=0.425499,    eval_loss=1.935563,    eval_acc=0.391484\n",
      "epoch:  58,    lr=0.000090,    loss=1.670040,    train_acc=0.429450,    eval_loss=1.932480,    eval_acc=0.399725\n",
      "epoch:  59,    lr=0.000089,    loss=1.661973,    train_acc=0.432442,    eval_loss=1.959900,    eval_acc=0.387878\n",
      "epoch:  60,    lr=0.000089,    loss=1.654483,    train_acc=0.434703,    eval_loss=1.924612,    eval_acc=0.401957\n",
      "epoch:  61,    lr=0.000089,    loss=1.643469,    train_acc=0.439452,    eval_loss=1.950968,    eval_acc=0.398867\n",
      "epoch:  62,    lr=0.000088,    loss=1.637098,    train_acc=0.442139,    eval_loss=1.927297,    eval_acc=0.405735\n",
      "epoch:  63,    lr=0.000088,    loss=1.630712,    train_acc=0.444242,    eval_loss=1.973541,    eval_acc=0.383757\n",
      "epoch:  64,    lr=0.000087,    loss=1.620228,    train_acc=0.448893,    eval_loss=1.921777,    eval_acc=0.397150\n",
      "epoch:  65,    lr=0.000087,    loss=1.612012,    train_acc=0.450359,    eval_loss=1.954182,    eval_acc=0.392771\n",
      "epoch:  66,    lr=0.000087,    loss=1.602952,    train_acc=0.454456,    eval_loss=1.922048,    eval_acc=0.408053\n",
      "epoch:  67,    lr=0.000086,    loss=1.596487,    train_acc=0.457831,    eval_loss=1.918256,    eval_acc=0.397064\n",
      "epoch:  68,    lr=0.000086,    loss=1.587443,    train_acc=0.461874,    eval_loss=1.925471,    eval_acc=0.399038\n",
      "epoch:  69,    lr=0.000086,    loss=1.579730,    train_acc=0.463296,    eval_loss=1.887528,    eval_acc=0.413977\n",
      "epoch:  70,    lr=0.000085,    loss=1.571067,    train_acc=0.466950,    eval_loss=1.920368,    eval_acc=0.406593\n",
      "epoch:  71,    lr=0.000085,    loss=1.565172,    train_acc=0.468610,    eval_loss=1.896129,    eval_acc=0.407709\n",
      "epoch:  72,    lr=0.000084,    loss=1.557838,    train_acc=0.471285,    eval_loss=1.889057,    eval_acc=0.404447\n",
      "epoch:  73,    lr=0.000084,    loss=1.548106,    train_acc=0.475644,    eval_loss=1.923538,    eval_acc=0.401185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  74,    lr=0.000084,    loss=1.541087,    train_acc=0.478952,    eval_loss=1.873883,    eval_acc=0.414148\n",
      "epoch:  75,    lr=0.000083,    loss=1.532715,    train_acc=0.481280,    eval_loss=1.875888,    eval_acc=0.418613\n",
      "epoch:  76,    lr=0.000083,    loss=1.520870,    train_acc=0.487251,    eval_loss=1.903984,    eval_acc=0.410628\n",
      "epoch:  77,    lr=0.000083,    loss=1.516512,    train_acc=0.487780,    eval_loss=1.918636,    eval_acc=0.407709\n",
      "epoch:  78,    lr=0.000082,    loss=1.509512,    train_acc=0.490017,    eval_loss=1.913148,    eval_acc=0.408139\n",
      "epoch:  79,    lr=0.000082,    loss=1.500561,    train_acc=0.493549,    eval_loss=1.896345,    eval_acc=0.431061\n",
      "epoch:  80,    lr=0.000081,    loss=1.491940,    train_acc=0.498729,    eval_loss=1.910759,    eval_acc=0.418870\n",
      "epoch:  81,    lr=0.000081,    loss=1.484959,    train_acc=0.499587,    eval_loss=1.894804,    eval_acc=0.422905\n",
      "epoch:  82,    lr=0.000081,    loss=1.475798,    train_acc=0.503690,    eval_loss=1.878491,    eval_acc=0.427284\n",
      "epoch:  83,    lr=0.000080,    loss=1.470932,    train_acc=0.505198,    eval_loss=1.889678,    eval_acc=0.424880\n",
      "epoch:  84,    lr=0.000080,    loss=1.462174,    train_acc=0.508998,    eval_loss=1.887854,    eval_acc=0.417668\n",
      "epoch:  85,    lr=0.000080,    loss=1.456261,    train_acc=0.510907,    eval_loss=1.875514,    eval_acc=0.425052\n",
      "epoch:  86,    lr=0.000079,    loss=1.449457,    train_acc=0.513479,    eval_loss=1.900193,    eval_acc=0.417153\n",
      "epoch:  87,    lr=0.000079,    loss=1.439566,    train_acc=0.516652,    eval_loss=1.916545,    eval_acc=0.416896\n",
      "epoch:  88,    lr=0.000079,    loss=1.432696,    train_acc=0.519200,    eval_loss=1.907266,    eval_acc=0.426597\n",
      "epoch:  89,    lr=0.000078,    loss=1.424202,    train_acc=0.523261,    eval_loss=1.905256,    eval_acc=0.426168\n",
      "epoch:  90,    lr=0.000078,    loss=1.420221,    train_acc=0.523024,    eval_loss=1.919192,    eval_acc=0.418784\n",
      "epoch:  91,    lr=0.000077,    loss=1.411661,    train_acc=0.525918,    eval_loss=1.913915,    eval_acc=0.420587\n",
      "epoch:  92,    lr=0.000077,    loss=1.404692,    train_acc=0.530119,    eval_loss=1.908015,    eval_acc=0.425652\n",
      "epoch:  93,    lr=0.000077,    loss=1.396409,    train_acc=0.532892,    eval_loss=1.887418,    eval_acc=0.427713\n",
      "epoch:  94,    lr=0.000076,    loss=1.389305,    train_acc=0.534472,    eval_loss=1.949436,    eval_acc=0.432005\n",
      "epoch:  95,    lr=0.000076,    loss=1.382658,    train_acc=0.536764,    eval_loss=1.933469,    eval_acc=0.424966\n",
      "epoch:  96,    lr=0.000076,    loss=1.373285,    train_acc=0.540576,    eval_loss=1.914249,    eval_acc=0.433980\n",
      "epoch:  97,    lr=0.000075,    loss=1.370149,    train_acc=0.541817,    eval_loss=1.926473,    eval_acc=0.431748\n",
      "epoch:  98,    lr=0.000075,    loss=1.360446,    train_acc=0.546218,    eval_loss=1.942544,    eval_acc=0.431490\n",
      "epoch:  99,    lr=0.000074,    loss=1.356032,    train_acc=0.547605,    eval_loss=1.898939,    eval_acc=0.434667\n",
      "epoch: 100,    lr=0.000074,    loss=1.349941,    train_acc=0.549714,    eval_loss=1.928002,    eval_acc=0.428915\n",
      "epoch: 101,    lr=0.000074,    loss=1.342129,    train_acc=0.553253,    eval_loss=1.934506,    eval_acc=0.435869\n",
      "epoch: 102,    lr=0.000073,    loss=1.332791,    train_acc=0.557484,    eval_loss=1.936738,    eval_acc=0.438187\n",
      "epoch: 103,    lr=0.000073,    loss=1.330281,    train_acc=0.556359,    eval_loss=1.924351,    eval_acc=0.439389\n",
      "epoch: 104,    lr=0.000073,    loss=1.320598,    train_acc=0.560250,    eval_loss=1.915850,    eval_acc=0.435611\n",
      "epoch: 105,    lr=0.000072,    loss=1.316886,    train_acc=0.561515,    eval_loss=1.908889,    eval_acc=0.441277\n",
      "epoch: 106,    lr=0.000072,    loss=1.311474,    train_acc=0.563017,    eval_loss=1.935243,    eval_acc=0.434753\n",
      "epoch: 107,    lr=0.000071,    loss=1.301964,    train_acc=0.566999,    eval_loss=1.943849,    eval_acc=0.434238\n",
      "epoch: 108,    lr=0.000071,    loss=1.294151,    train_acc=0.569692,    eval_loss=1.939342,    eval_acc=0.436813\n",
      "epoch: 109,    lr=0.000071,    loss=1.293283,    train_acc=0.569534,    eval_loss=1.932852,    eval_acc=0.439475\n",
      "epoch: 110,    lr=0.000070,    loss=1.286667,    train_acc=0.572215,    eval_loss=1.988398,    eval_acc=0.430546\n",
      "epoch: 111,    lr=0.000070,    loss=1.279907,    train_acc=0.577085,    eval_loss=1.946108,    eval_acc=0.442479\n",
      "epoch: 112,    lr=0.000070,    loss=1.274619,    train_acc=0.576532,    eval_loss=1.914620,    eval_acc=0.440934\n",
      "epoch: 113,    lr=0.000069,    loss=1.268073,    train_acc=0.579086,    eval_loss=1.980448,    eval_acc=0.440848\n",
      "epoch: 114,    lr=0.000069,    loss=1.263868,    train_acc=0.581372,    eval_loss=1.943658,    eval_acc=0.441106\n",
      "epoch: 115,    lr=0.000069,    loss=1.255877,    train_acc=0.582624,    eval_loss=1.972298,    eval_acc=0.442136\n",
      "epoch: 116,    lr=0.000068,    loss=1.249809,    train_acc=0.586193,    eval_loss=1.949895,    eval_acc=0.446085\n",
      "epoch: 117,    lr=0.000068,    loss=1.242962,    train_acc=0.587889,    eval_loss=2.028153,    eval_acc=0.427541\n",
      "epoch: 118,    lr=0.000067,    loss=1.237940,    train_acc=0.590297,    eval_loss=2.005977,    eval_acc=0.430460\n",
      "epoch: 119,    lr=0.000067,    loss=1.236665,    train_acc=0.589306,    eval_loss=1.969309,    eval_acc=0.443939\n",
      "epoch: 120,    lr=0.000067,    loss=1.226692,    train_acc=0.594401,    eval_loss=2.008762,    eval_acc=0.445398\n",
      "epoch: 121,    lr=0.000066,    loss=1.222251,    train_acc=0.596431,    eval_loss=2.003048,    eval_acc=0.421789\n",
      "epoch: 122,    lr=0.000066,    loss=1.219224,    train_acc=0.595610,    eval_loss=2.001057,    eval_acc=0.436470\n",
      "epoch: 123,    lr=0.000066,    loss=1.211517,    train_acc=0.600657,    eval_loss=1.987343,    eval_acc=0.449691\n",
      "epoch: 124,    lr=0.000065,    loss=1.207958,    train_acc=0.600182,    eval_loss=2.022656,    eval_acc=0.446343\n",
      "epoch: 125,    lr=0.000065,    loss=1.201501,    train_acc=0.602894,    eval_loss=2.021213,    eval_acc=0.452352\n",
      "epoch: 126,    lr=0.000064,    loss=1.196438,    train_acc=0.604694,    eval_loss=2.031451,    eval_acc=0.444196\n",
      "epoch: 127,    lr=0.000064,    loss=1.188524,    train_acc=0.607703,    eval_loss=2.013317,    eval_acc=0.447974\n",
      "epoch: 128,    lr=0.000064,    loss=1.186494,    train_acc=0.607654,    eval_loss=2.005684,    eval_acc=0.448832\n",
      "epoch: 129,    lr=0.000063,    loss=1.181524,    train_acc=0.610877,    eval_loss=1.994868,    eval_acc=0.449348\n",
      "epoch: 130,    lr=0.000063,    loss=1.177701,    train_acc=0.611503,    eval_loss=2.008600,    eval_acc=0.446944\n",
      "epoch: 131,    lr=0.000063,    loss=1.171652,    train_acc=0.614026,    eval_loss=2.011145,    eval_acc=0.448317\n",
      "epoch: 132,    lr=0.000062,    loss=1.165065,    train_acc=0.616738,    eval_loss=2.008450,    eval_acc=0.447974\n",
      "epoch: 133,    lr=0.000062,    loss=1.157775,    train_acc=0.617844,    eval_loss=2.040891,    eval_acc=0.447802\n",
      "epoch: 134,    lr=0.000061,    loss=1.157255,    train_acc=0.618726,    eval_loss=2.027826,    eval_acc=0.451322\n",
      "epoch: 135,    lr=0.000061,    loss=1.153282,    train_acc=0.620009,    eval_loss=2.046405,    eval_acc=0.447459\n",
      "epoch: 136,    lr=0.000061,    loss=1.146882,    train_acc=0.622915,    eval_loss=2.027127,    eval_acc=0.450378\n",
      "epoch: 137,    lr=0.000060,    loss=1.142187,    train_acc=0.624094,    eval_loss=2.069614,    eval_acc=0.445141\n",
      "epoch: 138,    lr=0.000060,    loss=1.137530,    train_acc=0.625511,    eval_loss=2.070921,    eval_acc=0.444540\n",
      "epoch: 139,    lr=0.000060,    loss=1.134445,    train_acc=0.627213,    eval_loss=2.040385,    eval_acc=0.455357\n",
      "epoch: 140,    lr=0.000059,    loss=1.129118,    train_acc=0.629055,    eval_loss=2.040529,    eval_acc=0.457074\n",
      "epoch: 141,    lr=0.000059,    loss=1.124232,    train_acc=0.631256,    eval_loss=2.055799,    eval_acc=0.448747\n",
      "epoch: 142,    lr=0.000059,    loss=1.117203,    train_acc=0.632253,    eval_loss=2.099330,    eval_acc=0.454327\n",
      "epoch: 143,    lr=0.000058,    loss=1.114205,    train_acc=0.635056,    eval_loss=2.031880,    eval_acc=0.454670\n",
      "epoch: 144,    lr=0.000058,    loss=1.110389,    train_acc=0.635080,    eval_loss=2.089932,    eval_acc=0.450206\n",
      "epoch: 145,    lr=0.000057,    loss=1.110090,    train_acc=0.635749,    eval_loss=2.080450,    eval_acc=0.450549\n",
      "epoch: 146,    lr=0.000057,    loss=1.101963,    train_acc=0.637457,    eval_loss=2.094373,    eval_acc=0.452095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 147,    lr=0.000057,    loss=1.095791,    train_acc=0.640315,    eval_loss=2.106446,    eval_acc=0.450464\n",
      "epoch: 148,    lr=0.000056,    loss=1.092413,    train_acc=0.641732,    eval_loss=2.149477,    eval_acc=0.449691\n",
      "epoch: 149,    lr=0.000056,    loss=1.087121,    train_acc=0.643975,    eval_loss=2.082643,    eval_acc=0.456044\n",
      "epoch: 150,    lr=0.000056,    loss=1.083828,    train_acc=0.645197,    eval_loss=2.121238,    eval_acc=0.452867\n",
      "epoch: 151,    lr=0.000055,    loss=1.081333,    train_acc=0.645610,    eval_loss=2.114948,    eval_acc=0.453039\n",
      "epoch: 152,    lr=0.000055,    loss=1.080386,    train_acc=0.645094,    eval_loss=2.120799,    eval_acc=0.451666\n",
      "epoch: 153,    lr=0.000054,    loss=1.071333,    train_acc=0.649897,    eval_loss=2.139597,    eval_acc=0.453468\n",
      "epoch: 154,    lr=0.000054,    loss=1.067260,    train_acc=0.652675,    eval_loss=2.138005,    eval_acc=0.449262\n",
      "epoch: 155,    lr=0.000054,    loss=1.067315,    train_acc=0.651763,    eval_loss=2.146136,    eval_acc=0.455958\n",
      "epoch: 156,    lr=0.000053,    loss=1.063572,    train_acc=0.651368,    eval_loss=2.130559,    eval_acc=0.461367\n",
      "epoch: 157,    lr=0.000053,    loss=1.059446,    train_acc=0.652961,    eval_loss=2.181815,    eval_acc=0.455786\n",
      "epoch: 158,    lr=0.000053,    loss=1.055325,    train_acc=0.655235,    eval_loss=2.126110,    eval_acc=0.459736\n",
      "epoch: 159,    lr=0.000052,    loss=1.048226,    train_acc=0.658974,    eval_loss=2.138139,    eval_acc=0.460251\n",
      "epoch: 160,    lr=0.000052,    loss=1.047992,    train_acc=0.657551,    eval_loss=2.148005,    eval_acc=0.458620\n",
      "epoch: 161,    lr=0.000051,    loss=1.044053,    train_acc=0.658998,    eval_loss=2.187016,    eval_acc=0.456216\n",
      "epoch: 162,    lr=0.000051,    loss=1.039018,    train_acc=0.661935,    eval_loss=2.155293,    eval_acc=0.458705\n",
      "epoch: 163,    lr=0.000051,    loss=1.035820,    train_acc=0.662731,    eval_loss=2.171248,    eval_acc=0.445484\n",
      "epoch: 164,    lr=0.000050,    loss=1.032043,    train_acc=0.663479,    eval_loss=2.177297,    eval_acc=0.455357\n",
      "epoch: 165,    lr=0.000050,    loss=1.028939,    train_acc=0.664920,    eval_loss=2.215320,    eval_acc=0.449863\n",
      "epoch: 166,    lr=0.000050,    loss=1.025182,    train_acc=0.666604,    eval_loss=2.194218,    eval_acc=0.455443\n",
      "epoch: 167,    lr=0.000049,    loss=1.022401,    train_acc=0.667595,    eval_loss=2.190624,    eval_acc=0.453383\n",
      "epoch: 168,    lr=0.000049,    loss=1.014486,    train_acc=0.670410,    eval_loss=2.204670,    eval_acc=0.456302\n",
      "epoch: 169,    lr=0.000049,    loss=1.017688,    train_acc=0.668695,    eval_loss=2.170358,    eval_acc=0.457074\n",
      "epoch: 170,    lr=0.000048,    loss=1.009964,    train_acc=0.671152,    eval_loss=2.217613,    eval_acc=0.459564\n",
      "epoch: 171,    lr=0.000048,    loss=1.010063,    train_acc=0.672191,    eval_loss=2.198153,    eval_acc=0.458276\n",
      "epoch: 172,    lr=0.000047,    loss=1.006226,    train_acc=0.673796,    eval_loss=2.214515,    eval_acc=0.459736\n",
      "epoch: 173,    lr=0.000047,    loss=0.999592,    train_acc=0.675450,    eval_loss=2.223592,    eval_acc=0.457503\n",
      "epoch: 174,    lr=0.000047,    loss=1.002291,    train_acc=0.674374,    eval_loss=2.242350,    eval_acc=0.452438\n",
      "epoch: 175,    lr=0.000046,    loss=0.992716,    train_acc=0.678289,    eval_loss=2.247538,    eval_acc=0.452524\n",
      "epoch: 176,    lr=0.000046,    loss=0.996130,    train_acc=0.675821,    eval_loss=2.226264,    eval_acc=0.463427\n",
      "epoch: 177,    lr=0.000046,    loss=0.989728,    train_acc=0.678259,    eval_loss=2.249089,    eval_acc=0.461538\n",
      "epoch: 178,    lr=0.000045,    loss=0.984583,    train_acc=0.679839,    eval_loss=2.212283,    eval_acc=0.458362\n",
      "epoch: 179,    lr=0.000045,    loss=0.987594,    train_acc=0.679821,    eval_loss=2.237523,    eval_acc=0.452266\n",
      "epoch: 180,    lr=0.000044,    loss=0.980862,    train_acc=0.681524,    eval_loss=2.229208,    eval_acc=0.459736\n",
      "epoch: 181,    lr=0.000044,    loss=0.973966,    train_acc=0.683834,    eval_loss=2.251454,    eval_acc=0.461710\n",
      "epoch: 182,    lr=0.000044,    loss=0.975100,    train_acc=0.683572,    eval_loss=2.309373,    eval_acc=0.452953\n",
      "epoch: 183,    lr=0.000043,    loss=0.973849,    train_acc=0.685159,    eval_loss=2.271042,    eval_acc=0.455958\n",
      "epoch: 184,    lr=0.000043,    loss=0.969860,    train_acc=0.686047,    eval_loss=2.222097,    eval_acc=0.459220\n",
      "epoch: 185,    lr=0.000043,    loss=0.966067,    train_acc=0.687123,    eval_loss=2.259706,    eval_acc=0.459220\n",
      "epoch: 186,    lr=0.000042,    loss=0.963159,    train_acc=0.687682,    eval_loss=2.275529,    eval_acc=0.460422\n",
      "epoch: 187,    lr=0.000042,    loss=0.962127,    train_acc=0.688369,    eval_loss=2.260568,    eval_acc=0.461367\n",
      "epoch: 188,    lr=0.000041,    loss=0.960054,    train_acc=0.688746,    eval_loss=2.297028,    eval_acc=0.451236\n",
      "epoch: 189,    lr=0.000041,    loss=0.953568,    train_acc=0.691847,    eval_loss=2.292226,    eval_acc=0.463084\n",
      "epoch: 190,    lr=0.000041,    loss=0.956716,    train_acc=0.690418,    eval_loss=2.288535,    eval_acc=0.458448\n",
      "epoch: 191,    lr=0.000040,    loss=0.949310,    train_acc=0.693762,    eval_loss=2.307147,    eval_acc=0.457847\n",
      "epoch: 192,    lr=0.000040,    loss=0.944226,    train_acc=0.695507,    eval_loss=2.320291,    eval_acc=0.460508\n",
      "epoch: 193,    lr=0.000040,    loss=0.943829,    train_acc=0.694808,    eval_loss=2.312578,    eval_acc=0.462740\n",
      "epoch: 194,    lr=0.000039,    loss=0.944413,    train_acc=0.694145,    eval_loss=2.310244,    eval_acc=0.454670\n",
      "epoch: 195,    lr=0.000039,    loss=0.939572,    train_acc=0.696127,    eval_loss=2.334435,    eval_acc=0.461710\n",
      "epoch: 196,    lr=0.000039,    loss=0.936794,    train_acc=0.696711,    eval_loss=2.350358,    eval_acc=0.460337\n",
      "epoch: 197,    lr=0.000038,    loss=0.933962,    train_acc=0.698504,    eval_loss=2.346609,    eval_acc=0.460165\n",
      "epoch: 198,    lr=0.000038,    loss=0.934274,    train_acc=0.698608,    eval_loss=2.338462,    eval_acc=0.460766\n",
      "epoch: 199,    lr=0.000037,    loss=0.929557,    train_acc=0.699805,    eval_loss=2.357103,    eval_acc=0.464200\n",
      "epoch: 200,    lr=0.000037,    loss=0.928990,    train_acc=0.699599,    eval_loss=2.340232,    eval_acc=0.461023\n",
      "epoch: 201,    lr=0.000037,    loss=0.925740,    train_acc=0.701289,    eval_loss=2.356055,    eval_acc=0.457933\n",
      "epoch: 202,    lr=0.000036,    loss=0.924995,    train_acc=0.701988,    eval_loss=2.334962,    eval_acc=0.463685\n",
      "epoch: 203,    lr=0.000036,    loss=0.921045,    train_acc=0.702997,    eval_loss=2.365306,    eval_acc=0.461109\n",
      "epoch: 204,    lr=0.000036,    loss=0.919418,    train_acc=0.702991,    eval_loss=2.357385,    eval_acc=0.464629\n",
      "epoch: 205,    lr=0.000035,    loss=0.920396,    train_acc=0.703465,    eval_loss=2.374073,    eval_acc=0.463513\n",
      "epoch: 206,    lr=0.000035,    loss=0.914774,    train_acc=0.705618,    eval_loss=2.355887,    eval_acc=0.461453\n",
      "epoch: 207,    lr=0.000034,    loss=0.907701,    train_acc=0.706597,    eval_loss=2.397524,    eval_acc=0.462225\n",
      "epoch: 208,    lr=0.000034,    loss=0.910075,    train_acc=0.705958,    eval_loss=2.359776,    eval_acc=0.466003\n",
      "epoch: 209,    lr=0.000034,    loss=0.909176,    train_acc=0.707138,    eval_loss=2.393871,    eval_acc=0.461710\n",
      "epoch: 210,    lr=0.000033,    loss=0.904920,    train_acc=0.709460,    eval_loss=2.390716,    eval_acc=0.463942\n",
      "epoch: 211,    lr=0.000033,    loss=0.903835,    train_acc=0.708767,    eval_loss=2.396366,    eval_acc=0.457418\n",
      "epoch: 212,    lr=0.000033,    loss=0.901698,    train_acc=0.709740,    eval_loss=2.431088,    eval_acc=0.460852\n",
      "epoch: 213,    lr=0.000032,    loss=0.898798,    train_acc=0.710755,    eval_loss=2.422230,    eval_acc=0.464028\n",
      "epoch: 214,    lr=0.000032,    loss=0.897332,    train_acc=0.710804,    eval_loss=2.380709,    eval_acc=0.467977\n",
      "epoch: 215,    lr=0.000031,    loss=0.896405,    train_acc=0.711673,    eval_loss=2.410849,    eval_acc=0.466003\n",
      "epoch: 216,    lr=0.000031,    loss=0.896322,    train_acc=0.711400,    eval_loss=2.420488,    eval_acc=0.461796\n",
      "epoch: 217,    lr=0.000031,    loss=0.892051,    train_acc=0.712062,    eval_loss=2.442444,    eval_acc=0.460251\n",
      "epoch: 218,    lr=0.000030,    loss=0.889950,    train_acc=0.713260,    eval_loss=2.413550,    eval_acc=0.458362\n",
      "epoch: 219,    lr=0.000030,    loss=0.887140,    train_acc=0.715236,    eval_loss=2.423828,    eval_acc=0.463170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 220,    lr=0.000030,    loss=0.885250,    train_acc=0.714087,    eval_loss=2.429128,    eval_acc=0.464973\n",
      "epoch: 221,    lr=0.000029,    loss=0.888698,    train_acc=0.713783,    eval_loss=2.454234,    eval_acc=0.457675\n",
      "epoch: 222,    lr=0.000029,    loss=0.884226,    train_acc=0.715163,    eval_loss=2.422917,    eval_acc=0.461624\n",
      "epoch: 223,    lr=0.000029,    loss=0.882141,    train_acc=0.716288,    eval_loss=2.432266,    eval_acc=0.460508\n",
      "epoch: 224,    lr=0.000028,    loss=0.878265,    train_acc=0.717370,    eval_loss=2.472215,    eval_acc=0.462139\n",
      "epoch: 225,    lr=0.000028,    loss=0.879007,    train_acc=0.716999,    eval_loss=2.457587,    eval_acc=0.463084\n",
      "epoch: 226,    lr=0.000027,    loss=0.873463,    train_acc=0.719705,    eval_loss=2.479204,    eval_acc=0.464200\n",
      "epoch: 227,    lr=0.000027,    loss=0.875764,    train_acc=0.717741,    eval_loss=2.465697,    eval_acc=0.459392\n",
      "epoch: 228,    lr=0.000027,    loss=0.873790,    train_acc=0.718191,    eval_loss=2.495329,    eval_acc=0.462912\n",
      "epoch: 229,    lr=0.000026,    loss=0.867131,    train_acc=0.720823,    eval_loss=2.500788,    eval_acc=0.461968\n",
      "epoch: 230,    lr=0.000026,    loss=0.870442,    train_acc=0.720203,    eval_loss=2.482340,    eval_acc=0.463856\n",
      "epoch: 231,    lr=0.000026,    loss=0.868816,    train_acc=0.720154,    eval_loss=2.477891,    eval_acc=0.467462\n",
      "epoch: 232,    lr=0.000025,    loss=0.868119,    train_acc=0.721918,    eval_loss=2.485692,    eval_acc=0.470553\n",
      "epoch: 233,    lr=0.000025,    loss=0.863608,    train_acc=0.721668,    eval_loss=2.523240,    eval_acc=0.461710\n",
      "epoch: 234,    lr=0.000024,    loss=0.863594,    train_acc=0.723255,    eval_loss=2.515383,    eval_acc=0.464286\n",
      "epoch: 235,    lr=0.000024,    loss=0.857774,    train_acc=0.724441,    eval_loss=2.507821,    eval_acc=0.467119\n",
      "epoch: 236,    lr=0.000024,    loss=0.860946,    train_acc=0.723729,    eval_loss=2.508384,    eval_acc=0.463427\n",
      "epoch: 237,    lr=0.000023,    loss=0.860493,    train_acc=0.723669,    eval_loss=2.517702,    eval_acc=0.460766\n",
      "epoch: 238,    lr=0.000023,    loss=0.856797,    train_acc=0.724204,    eval_loss=2.498621,    eval_acc=0.467977\n",
      "epoch: 239,    lr=0.000023,    loss=0.856903,    train_acc=0.724824,    eval_loss=2.505863,    eval_acc=0.465316\n",
      "epoch: 240,    lr=0.000022,    loss=0.855411,    train_acc=0.725462,    eval_loss=2.516575,    eval_acc=0.465058\n",
      "epoch: 241,    lr=0.000022,    loss=0.858371,    train_acc=0.724818,    eval_loss=2.517704,    eval_acc=0.469265\n",
      "epoch: 242,    lr=0.000021,    loss=0.848778,    train_acc=0.728016,    eval_loss=2.519489,    eval_acc=0.465917\n",
      "epoch: 243,    lr=0.000021,    loss=0.849835,    train_acc=0.727018,    eval_loss=2.538498,    eval_acc=0.468149\n",
      "epoch: 244,    lr=0.000021,    loss=0.845869,    train_acc=0.729067,    eval_loss=2.520819,    eval_acc=0.464973\n",
      "epoch: 245,    lr=0.000020,    loss=0.848102,    train_acc=0.727401,    eval_loss=2.535093,    eval_acc=0.465144\n",
      "epoch: 246,    lr=0.000020,    loss=0.844062,    train_acc=0.729651,    eval_loss=2.561364,    eval_acc=0.458448\n",
      "epoch: 247,    lr=0.000020,    loss=0.844134,    train_acc=0.729238,    eval_loss=2.536212,    eval_acc=0.465831\n",
      "epoch: 248,    lr=0.000019,    loss=0.842840,    train_acc=0.729244,    eval_loss=2.567601,    eval_acc=0.463341\n",
      "epoch: 249,    lr=0.000019,    loss=0.842254,    train_acc=0.728909,    eval_loss=2.550999,    eval_acc=0.462397\n",
      "epoch: 250,    lr=0.000019,    loss=0.841030,    train_acc=0.730295,    eval_loss=2.578561,    eval_acc=0.467205\n",
      "epoch: 251,    lr=0.000018,    loss=0.839940,    train_acc=0.730812,    eval_loss=2.567286,    eval_acc=0.466690\n",
      "epoch: 252,    lr=0.000018,    loss=0.837930,    train_acc=0.730612,    eval_loss=2.560797,    eval_acc=0.464114\n",
      "epoch: 253,    lr=0.000017,    loss=0.840337,    train_acc=0.730180,    eval_loss=2.547882,    eval_acc=0.469523\n",
      "epoch: 254,    lr=0.000017,    loss=0.834413,    train_acc=0.733135,    eval_loss=2.602559,    eval_acc=0.463771\n",
      "epoch: 255,    lr=0.000017,    loss=0.833726,    train_acc=0.731888,    eval_loss=2.588149,    eval_acc=0.467291\n",
      "epoch: 256,    lr=0.000016,    loss=0.833635,    train_acc=0.733639,    eval_loss=2.573405,    eval_acc=0.465831\n",
      "epoch: 257,    lr=0.000016,    loss=0.833163,    train_acc=0.732332,    eval_loss=2.574540,    eval_acc=0.466346\n",
      "epoch: 258,    lr=0.000016,    loss=0.832312,    train_acc=0.733493,    eval_loss=2.562166,    eval_acc=0.467720\n",
      "epoch: 259,    lr=0.000015,    loss=0.832081,    train_acc=0.733189,    eval_loss=2.602310,    eval_acc=0.464715\n",
      "epoch: 260,    lr=0.000015,    loss=0.826532,    train_acc=0.734472,    eval_loss=2.588314,    eval_acc=0.467720\n",
      "epoch: 261,    lr=0.000014,    loss=0.826838,    train_acc=0.734819,    eval_loss=2.572946,    eval_acc=0.467291\n",
      "epoch: 262,    lr=0.000014,    loss=0.826768,    train_acc=0.734831,    eval_loss=2.591631,    eval_acc=0.462912\n",
      "epoch: 263,    lr=0.000014,    loss=0.827621,    train_acc=0.735068,    eval_loss=2.584199,    eval_acc=0.465745\n",
      "epoch: 264,    lr=0.000013,    loss=0.824912,    train_acc=0.735706,    eval_loss=2.610968,    eval_acc=0.467119\n",
      "epoch: 265,    lr=0.000013,    loss=0.825385,    train_acc=0.735822,    eval_loss=2.591837,    eval_acc=0.467205\n",
      "epoch: 266,    lr=0.000013,    loss=0.820428,    train_acc=0.736795,    eval_loss=2.614750,    eval_acc=0.464372\n",
      "epoch: 267,    lr=0.000012,    loss=0.822937,    train_acc=0.736734,    eval_loss=2.599835,    eval_acc=0.466260\n",
      "epoch: 268,    lr=0.000012,    loss=0.821468,    train_acc=0.737305,    eval_loss=2.610067,    eval_acc=0.468578\n",
      "epoch: 269,    lr=0.000011,    loss=0.820384,    train_acc=0.737269,    eval_loss=2.616658,    eval_acc=0.466346\n",
      "epoch: 270,    lr=0.000011,    loss=0.817959,    train_acc=0.738904,    eval_loss=2.622181,    eval_acc=0.465058\n",
      "epoch: 271,    lr=0.000011,    loss=0.819614,    train_acc=0.738284,    eval_loss=2.628468,    eval_acc=0.465573\n",
      "epoch: 272,    lr=0.000010,    loss=0.816394,    train_acc=0.738910,    eval_loss=2.609015,    eval_acc=0.466089\n",
      "epoch: 273,    lr=0.000010,    loss=0.816622,    train_acc=0.738868,    eval_loss=2.627847,    eval_acc=0.467977\n",
      "epoch: 274,    lr=0.000010,    loss=0.815730,    train_acc=0.738667,    eval_loss=2.623785,    eval_acc=0.463170\n",
      "epoch: 275,    lr=0.000009,    loss=0.812901,    train_acc=0.739433,    eval_loss=2.627932,    eval_acc=0.465573\n",
      "epoch: 276,    lr=0.000009,    loss=0.814806,    train_acc=0.739269,    eval_loss=2.627878,    eval_acc=0.467119\n",
      "epoch: 277,    lr=0.000009,    loss=0.811014,    train_acc=0.739725,    eval_loss=2.618746,    eval_acc=0.467634\n",
      "epoch: 278,    lr=0.000008,    loss=0.811894,    train_acc=0.740582,    eval_loss=2.622467,    eval_acc=0.462483\n",
      "epoch: 279,    lr=0.000008,    loss=0.814058,    train_acc=0.739628,    eval_loss=2.632126,    eval_acc=0.466861\n",
      "epoch: 280,    lr=0.000007,    loss=0.809879,    train_acc=0.741069,    eval_loss=2.639860,    eval_acc=0.465230\n",
      "epoch: 281,    lr=0.000007,    loss=0.808124,    train_acc=0.742005,    eval_loss=2.645363,    eval_acc=0.463685\n",
      "epoch: 282,    lr=0.000007,    loss=0.808312,    train_acc=0.741859,    eval_loss=2.643986,    eval_acc=0.469523\n",
      "epoch: 283,    lr=0.000006,    loss=0.806826,    train_acc=0.741774,    eval_loss=2.626974,    eval_acc=0.466775\n",
      "epoch: 284,    lr=0.000006,    loss=0.810231,    train_acc=0.741215,    eval_loss=2.631727,    eval_acc=0.465230\n",
      "epoch: 285,    lr=0.000006,    loss=0.806637,    train_acc=0.741732,    eval_loss=2.649183,    eval_acc=0.466003\n",
      "epoch: 286,    lr=0.000005,    loss=0.807801,    train_acc=0.741464,    eval_loss=2.655184,    eval_acc=0.467119\n",
      "epoch: 287,    lr=0.000005,    loss=0.808490,    train_acc=0.742194,    eval_loss=2.643883,    eval_acc=0.463255\n",
      "epoch: 288,    lr=0.000004,    loss=0.803726,    train_acc=0.743446,    eval_loss=2.647771,    eval_acc=0.467376\n",
      "epoch: 289,    lr=0.000004,    loss=0.807783,    train_acc=0.741537,    eval_loss=2.641974,    eval_acc=0.466947\n",
      "epoch: 290,    lr=0.000004,    loss=0.807017,    train_acc=0.741798,    eval_loss=2.648838,    eval_acc=0.463599\n",
      "epoch: 291,    lr=0.000003,    loss=0.803226,    train_acc=0.744188,    eval_loss=2.671250,    eval_acc=0.469179\n",
      "epoch: 292,    lr=0.000003,    loss=0.803409,    train_acc=0.743178,    eval_loss=2.647763,    eval_acc=0.467977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 293,    lr=0.000003,    loss=0.803106,    train_acc=0.743580,    eval_loss=2.656069,    eval_acc=0.466260\n",
      "epoch: 294,    lr=0.000002,    loss=0.803341,    train_acc=0.744054,    eval_loss=2.651335,    eval_acc=0.467548\n",
      "epoch: 295,    lr=0.000002,    loss=0.804417,    train_acc=0.742753,    eval_loss=2.650808,    eval_acc=0.465058\n",
      "epoch: 296,    lr=0.000001,    loss=0.800301,    train_acc=0.744261,    eval_loss=2.657105,    eval_acc=0.467462\n",
      "epoch: 297,    lr=0.000001,    loss=0.803624,    train_acc=0.743878,    eval_loss=2.655103,    eval_acc=0.468922\n",
      "epoch: 298,    lr=0.000001,    loss=0.798566,    train_acc=0.744942,    eval_loss=2.653604,    eval_acc=0.468664\n",
      "epoch: 299,    lr=0.000000,    loss=0.800968,    train_acc=0.744352,    eval_loss=2.639532,    eval_acc=0.471240\n",
      "epoch: 300,    lr=0.000000,    loss=0.798525,    train_acc=0.745623,    eval_loss=2.652670,    eval_acc=0.467634\n"
     ]
    }
   ],
   "source": [
    "train(train_dataloader, eval_dataloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "if(multi_task == 'true'):\n",
    "    model_g.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "n = 0\n",
    "\n",
    "for i in range(len(eval_samples)):\n",
    "    try:\n",
    "        X_new = preprocessing(eval_samples[i], method='mfcc', sr=16000, n_mfcc=n_mfcc)\n",
    "        X_new = convert_tensor(X_new).to(device)\n",
    "        y_new = model(X_new)\n",
    "        y_new = torch.argmax(nn.Softmax(dim=-1)(torch.mean(y_new, dim=0)))\n",
    "        #y_new = sorted(dict(collections.Counter(torch.argmax(nn.Softmax(dim=-1)(y_new), dim=1).cpu().numpy()))\n",
    "        #               .items(), key=(lambda x: x[1]), reverse=True)[0][0]\n",
    "        y_new = 1 if (y_new.item() == y[eval_idx][i].item()) else 0\n",
    "        correct += y_new\n",
    "        n += 1\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "acc = correct / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuray: 0.85278\n"
     ]
    }
   ],
   "source": [
    "print('Test accuray:', round(acc, 5))  # 0.7111"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1DCNN  \n",
    "Test accuray: 0.64722"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(eval_samples) - set(train_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl",
   "language": "python",
   "name": "mldl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
